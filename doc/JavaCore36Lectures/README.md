### Java核心36讲

#### 1、对Java平台的理解

##### 一、如何理解java是解释执行的？

​	java的”书写一次，到处执行“是基于jvm的，通过字节码文件将不同系统下的jvm翻译成机器码执行。

​	还有一种情况就是通过JIT编译器将热点代码直接编译为机器码，所以就不全是解释执行了。

##### 二、知识扩展

- java基本语言特性：面向对象、反射、泛型、集合、lambda等

- 基础类库：包括集合、io/nio、网络、并发、安全等

- jvm基础概念和机制有类加载机制、垃圾回收机制、运行时、动态编译等。

- 辅助工具有jlink、jar、jdeps。

- 编译器javac、sjavac。

- 诊断工具jmap、jstack、jconsole、jhsdb、jcmd等。

#### 2、Exception和Error有什么区别？

##### 一、典型回答

​	Exception和Error都是继承了Throwable类，而只有Throwable类型的实例才可以被抛出(throw)和捕获(catch)，是异常处理机制的基本组成类型。

​	Exception表示可预料的意外情况，可以进行处理，如算术异常等。Error表示不可预料的意外情况，很难被处理，如堆栈溢出等。

​	Exception又分为可检查异常和不检查异常，可检查异常在源码里必须显示地进行捕获处理，而不检查异常又称运行时异常，例如空指针异常等，通常是编码逻辑错误的异常，可以有选择的捕获。

##### 二、知识扩展

​	掌握基本语法：try-catch-finally、throw、throws关键字，语法糖try-with-resources、multiple catch，close扩展AutoCloseable、Closeable对象。

##### 三、实战场景

​	1、尽量不要捕获类似Exception通用异常，应该捕获特定异常。
​		抛出异常是需要进行处理和解决的，而使用通用异常会隐藏掉重要的异常信息，对处理异常和团队协作是很不友好的。

​	2、不要生吞(swallow)异常。
​		不要忽视可能发生的异常的代码块。对于异常最好使用产品日志，将详细输出到日志系统里。

​	3、Throw early,catch late原则
​		如果第一时间没有进行异常的捕捉或抛出，那么一但报错，堆栈信息繁多，往往很难快速定位到问题所在。如果对异常进行捕捉，确不知道怎么处理，应该选择保留原有异常的信息，再往上抛出异常。当上层捕捉异常时，业务往往会更清楚怎么做处理。

​	4、自定义异常
​		需要考虑到充足的异常信息，并进行异常分类。
​		考虑到敏感信息，确保安全问题。

##### 四、建议

​	由于try-cath会产出额外的性能开销，建议不要直接捕获整块代码，而是捕获有必要的代码，JVM性能优化点。

#### 3、final、finally、finalize有什么不同？

##### 一、经典回答

​	final修饰的类不可被继承，final的变量是不可被修改，final的方法是不可重写。

​	finally则是java保证重点代码一定要被执行的一种机制。使用try-finally或者try-catch-finally来进行类似JDBC连接、保证unlock锁等动作。

​	finalize是基础类Object的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize机制现在已经不推荐使用，并且在JDK9开始被标记为deprecated。

##### 二、实战场景

​	final的类可以有效避免API使用者更改基础功能，保证平台安全。final的变量可以避免意外赋值导致的编程错误，还可以用于保护只读数据，在并发编程中可以减少额外的同步开销，也可以省去一些防御性拷贝的必要。final的引用变量的对象是可以被改变的，而非真正的immutable。如果真要实现immutable的类，那么需要做到：
​	1、将class声明为final，不能通过扩展来绕过限制。
​	2、成员变量定义为private和final，并且不要实现setter方法。
​	3、使用深度拷贝来初始化，因为无法确定输入对象不被其他人修改。
​	4、实现getter方法时，使用copy-on-write原则，创建私有的copy。

​	finally可以用于关闭连接等资源，但更推荐使用java7中添加的try-with-resources语句，因为java平台能够更好的处理异常情况，编码量也要少很多。

​	finalize已经不推荐使用了，由于finalize被设计成在对象被垃圾收集前调用，jvm要对它进行额外处理，从而降低了垃圾回收的效率。在源码实现上，finalize是直接生吞了Throwable，掩盖了出错信息。建议使用Cleaner类来代替finalize。

#### 4、强引用、软引用、弱引用、幻像引用有什么区别？

##### 一、经典回答

​	引用类型体现的是对象不同的可达性(reachable)状态和对垃圾收集的影响。

​	强引用("Strong" Reference)指向的对象表明是活的，垃圾收集器不会碰他。

​	软引用(SoftReference)是一种相对强引用弱化一些的引用，只有当jvm认为内存不足时，才会试图回收软引用指向的对象。常用于缓存。

​	弱引用(WeakReference)并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。比如维护一种非强制性的映射关系，如果试图获取时对象存在，就使用它，否则重新实例化。常用于缓存。

​	幻像引用也叫作虚引用，不能通过它访问对象。仅仅是提供了一种确保对象被finalize以后，做某些事情的机制。比如通常来做所谓的Post-Mortem清除机制。利用幻像引用监控对象的创建和销毁。

##### 二、知识扩展

> 1、对象可达性状态流转

​	判断对象可达性，是JVM垃圾收集器决定如何处理对象的一部分考虑。利用软引用和弱引用，可以将访问到的对象重新指向强引用，一但错误的保持了强引用(比如赋值给了static变量)，那么对象就没有机会变回弱引用，就会产生内存泄漏。所以检查弱引用指向对象是否被垃圾收集，也是诊断是否有特定内存泄漏的一个思路。

> 2、引用队列(ReferenceQueue)使用

​	jvm会在特定时机将引用enqueue到队列里，我们就可以从队列里获取引用进行相关后续逻辑。

> 3、显式地影响引用垃圾收集

​	软引用通常会在最后一次引用后，还能保持一段时间，可以设置默认保持的时间。

> 4、诊断JVM引用情况

​	如果怀疑应用存在引用（或 finalize）导致的回收问题，可以有很多工具或者选项可供选择。比如HotSpot JVM 自身便提供了明确的选项（PrintReferenceGC）去获取相关信息，不过JDK 9 对 JVM 和垃圾收集日志进行了广泛的重构，类似PrintGCTimeStamps 和 PrintReferenceGC 已经不再存在。

> 5、Reachability Fence

​	在java9中利用java.lang.ref.Reference类下的reachabilityFence方法，可以在没有强引用情况下，通知 JVM 对象是在被使用的。reachability 保障的代码段利用 try-finally 包围起来，在 finally 里明确声明对象强可达。

#### 5、String、StringBuffer、StringBuilder有什么区别？

##### 一、经典回答

​	String是典型的Immutable类，被声明成为final class。由于它的不可变性，类似拼接、裁剪字符串等动作都会产生新的对象，所以相关操作的效率对应用性能会有明显的影响。

​	StringBuffer是为了解决上面提到拼接产生太多中间对象的问题而提供的一个类。本质是一个线程安全的可修改字符序列，保证了线程安全，也随之带来了额外的性能开销。

​	StringBuilder是java1.5中新增的，在能力上和StringBuffer没有本质区别，但是他去掉了线程安全的部分，有效减小了开销。

##### 二、知识扩展

> 1、字符串设计和实现考量

​	String原生的保证了基础线程安全，由于不可变，在进行对象拷贝时不需要额外复制数据。

​	StringBuffer实现的一些细节，线程安全是通过把各种修改数据的方法都加上了synchronized关键字实现的。简单粗暴，不必纠结于性能，有人说“过早优化，是万恶之源”。

​	StringBuffer和StringBuilder底层都是利用了可修改的char数组，从而达到修改序列的目的。char数组默认大小是16，最好在可预知情况下指定合适大小，避免扩容带来的额外开销。二者都继承了AbstractStringBuilder，里面包含了基本操作，区别在于最终方法是否加了synchronized。

> 2、字符串缓存

​	String在java6以后提供了intern()方法，其目的是提示JVM把相应字符串缓存起来，以备重复使用。然而被缓存的字符串是存在PermGen永久代的，基本不会被FullGC之外的垃圾收集器收集。所以使用不当，OOM就会光顾。

​	在后续版本中，这个缓存被放置在堆中，也就极大避免了永久代占满的问题，甚至永久代在jdk8中被MetaSpace(元数据区)代替了。缓存大小从1009修改为60013。

​	intern是一种显示地排重机制，但是它有一定的副作用，需要开发者写代码是明确调用，不方便，及很难预计字符串的重复情况，是一种污染代码的实践。幸好在jdk8u20之后，推出的一个新特性，也就是G1 GC下的字符串排重。它是通过将相同数据的字符串指向同一份数据来做到的，是JVM底层的改变。

> 3、String自身的演化

​	字符串在历史版本中，它是使用char数组来存储数据的。而char是占两个bytes大小，对于占一个bytes大小的字符就造成了一定的浪费。其实在java6时候Oraclejdk提供了压缩字符串的特性，但是这个特性的实现并不是开源的，而且在实践中也暴露出了一些问题，所以在最新的jdk版本中已经将它移除。

​	在java9中引入了CompactStrings的设计，将数据存储方式从char数组，改变为一个byte数组加上一个标识编码的所谓coder，并且将相关字符串操作类都进行了修改。另外，所有相关的intrinsic类也进行了重写，以保证没有任何性能损失。

​	仅仅是字符串一个实现，就需要 Java 平台工程师和科学家付出如此大且默默无闻的努力，我们得到的很多便利都是来源于此。

#### 6、动态代理是基于什么原理？

> 编程语言分类的角度

- 动态类型和静态类型：就是语言类型信息是在运行时检查，还是在编译期检查。
- 强类型和弱类型：就是在不同类型变量赋值时，是否需要显示地进行类型转换。

> java是静态的强类型语言，但是因为提供了类似反射等机制，也具备了部分动态类型语言的能力。

##### 一、经典回答

​	反射机制是java语言提供的一种基础功能，赋予程序在运行时自省(imtrospect,官方用语)的能力。

​	通过反射可以直接操作类或者对象，获取类的属性和方法，调用方法或者构造方法，甚至可以运行时修改类定义。

​	动态代理是一种方便运行时动态构建代理、动态处理代理方法调用的机制，比如用来包装RPC调用、面向切面的编程(AOP)。实现方式有JDK自身提供的动态代理，还有高性能的字节码操作机制，类似ASM、cglib(基于ASM)、javassist等。

##### 二、知识扩展

​	反射的setAccessible方法可以修改成员的访问限制，比如在ORM框架中，利用反射在运行时自动生成setter、getter方法。使用反射绕过API访问控制。

​	在java9以后，这个方法的使用可能存在一些争议，因为jigsaw项目新增的模块化系统，出于强封装性的考虑，对反射访问进行了限制。只有当被反射操作的模块和指定的包，对反射调用者模块open才能使用。

​	因为反射机制使用广泛，根据社区讨论，目前java9仍然保留了兼容java8的行为，但很有可能在未来版本完全启动对该方法的限制。

​	动态代理是一个代理机制，可以让调用者与实现者之间解耦。jDK动态代理是以接口为中心的，且实例化的是Proxy对象，而不是真正的被调用类型，有时候调用目标可能不便于实现额外接口，这在实践中还是可能带来各种不便和能力退化。好处是代码实现简单、jdk自身的支持、可靠性、易维护。

	cglib动态代理采取的是创建目标类的子类的方式，近似于调用者本身的效果，只操作关心的类，高性能，无限制。
#### 7、int和Integer有什么区别？

##### 一、经典回答

​	java语言虽然号称一切都是对象，但原始数据类型是例外。

​	Interger是int的包装类，它有一个int类型的字段存储数据，并且提供了基本操作。比如数学运算、int和字符串之间转换等。在java5中，引入了自动装箱和自动拆箱功能(boxing/unboxing)，新增了静态工厂方法valueOf，在调用它的时候会利用一个缓存机制，默认缓存是-128到127之间。

##### 二、知识扩展

> 1、理解自动装箱、拆箱

​		java中1默认是int类型，直接赋值给Integer会进行自动装箱操作valueOf()。将Integer类型数据赋值给int，就会进行自动拆箱intValue()。

​		Byte、Short都是缓存-128到127之间的数值。Boolean，缓存true/false，确切是返回两个常量实例Boolean.TRUE/FALSE。Character，缓存范围'\u0000'到'\u007F'。

> 2、源码分析

​		JVM提供了参数设置，可以调整缓存的大小。Integer等包装类型都被声明为private final，并定义了类似SIZE或者BYTES这样的常量。

> 3、原始类型线程安全	

​		考虑到线程安全问题，可以使用AtomicInteger、AtomicLong这样的线程安全类。

> 4、原始数据类型和引用类型的局限性

​		原始数据类型和java泛型并不能配合使用，因为这只是一个编译期的技巧。无法高效地表达数据，也不便于表达复杂的数据结构，比如vector和tuple。

​		java为对象内建了各种多态、线程安全等方面的支持，但这不是所有场合的需求，尤其是数据处理重要性日益提高，更加密度的值类型是非常现实的需求。针对这些方面的增强，目前正在OpenJDK领域紧锣密鼓地进行开发。

##### 三、对象的内存结构

​	在HotSpot虚拟机中，对象分为对象头(Header)、实例数据(instance Data)和对齐填充(Padding)。

> 1、对象头包含两部分信息

​	第一部分用于存储对象自身的运行时数据，如哈希码(HashCode)、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据分别在32位和64位虚拟机(未开启压缩指针)中分别为23bit和64bit，官方称它为"Mark Word"。

​	第二部分是指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定对象是哪个类的实例。如果对象是一个java数组，那么对象头还必须有一块用于记录数组长度的数据，因为虚拟机无法通过元数据确认数组的大小。

> 2、实例数据

​	实例数据是对象真正存储的有效信息，也是程序代码中所定义的各种类型的字段内容，无论是从父类继承下来的，还是在子类定义的，都需要记录起来。

> 3、对齐填充

	对齐填充不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。HotSpotVM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，也就是对象的大小必须是8字节的整数倍。
#### 8、Vector、ArrayList、LinkedList有何区别？

##### 一、经典回答

​	三者都是实现集合框架中的List，也就是所谓的有序集合，因此具体功能也比较近似，比如都提供按照位置进行定位、添加或者删除的操作，都是提供迭代器以遍历其内容等。

​	Vector是java早期提供的线程安全的动态数组。

​	ArrayList是应用更加广泛的动态数组，因为它本身不是线程安全的，所以性能要好很多。Vector在扩容时会提高1倍，而ArrayList则是增加50%。

​	LinkedList顾名思义是java提供的双向链表，所以它不需要像上面两种那样调整容量，它也不是线程安全的。

##### 二、知识扩展

> 1、集合框架

​		Collection分别了三大类集合，List、Set、Queue/Deque。通常概念上会把Map作为集合框架的一部分，但是它本身并不是真正的集合(Collection)。除了java.util.concurrent下的线程安全容器外，容器还可以通过Collections工具类中的synchronizedList方法来添加基本的同步支持，非常简单粗暴，但也非常实用。

> 2、排序

​		java提供的默认排序算法Arrays.sort和Collections.sort(底层调用Arrays.sort)。对于原始数据类型，目前使用所谓双轴快速排序(Dual-Pivot QuickSort)，是一中改进的快速排序算法。对于对象数据类型，目前则是使用的TimSort，思想上也是一种归并和二分插入排序(binarySort)结合的优化排序算法。
​		另外，java8引入了并行排序算法(直接使用parallelSort方法)，这是为了充分利用现代多核处理器的计算能力，底层实现基于fork-join框架，当数据集增长到数万或百万以上时，提高就非常大了。排序算法仍然在不断改进，最近双轴快速排序实现的作者提交了一个更进一步的改进，目前还在审核和验证阶段，根据作者的性能测试对比，相比基于归并排序的实现，新改进可以提高随机数据集排序速度提高10%-20%，甚至在其他特征的数据集上也有几倍的提高。

> 3、新特性

​		在java8之中，java平台支持了Lambda和Stream函数式编程，相应的java集合框架也进行了大范围的增强，以支持类似为集合创建相应stream或者parallelStream的方法实现，更加方便实现函数式代码。

		在java9中，java标准类库提供了一系列的静态工厂方法，比如List.of()、Set.of()。根据业界实践经验，一部分集合实例容量非常有限，且在生命周期中不会进行修改。通过List.of("Hello","world");一行代码就够了，且保证了不可变性。of方法已经支持了所谓的可变参数(varargs)，但官方类库还是提供了一系列特定参数长度的方法，其实这是为了最优的性能，JVM在处理边长参数的时候会有明显的额外开销。
 #### 9、HashTable、HashMap、TreeMap 有什么不同？

##### 一、经典回答

​	HashTable、HashMap、TreeMap都是最常见的一些Map实现，是以键值对的形式存储和操作数据的容器类型。

​	HashTable是早期java类库提供的一个哈希表实现，本身是同步的，不支持null键和值，由于同步导致的性能开销，所以已经很少被推荐使用。

​	HashMap是应用更加广泛的哈希表实现，行为大致上与HashTable一致，主要区别在于，不是同步的，支持null键和值等，进行get或put操作可以达到常数时间的性能，所以它是绝大部分利用键值对存取场景的首选。

​	TreeMap则是基于红黑树的一种提供顺序访问的Map，和HashMap不同，它的get、put、remove之类操作都是O(logn)的时间复杂度，具体顺序可以由指定的Comparator来决定，或者根据键的自然顺序来判断。

##### 二、知识扩展

​	HashMap的性能表现非常依赖于哈希码的有效性。equals相等，hashCode一定要相等，也就是哈希一致性。这也就是为什么重写了hashCode也要重写equals的原因。equals的对称、反射、传递等特性。

​	HashMap是数组+单链表实现的，键值存储是无序的。而LinkedHashMap继承了HashMap，保证了插入顺序。

​	虽然LinkedHashMap和TreeMap都可以保证某种顺序，但二者还是非常不同的。LinkedHashMap通常提供的是遍历符合插入顺序，并且实现了LRU缓存淘汰算法，实现是通过数组+双向链表的方式。TreeMap实现了SortMap，默认按照键自然排序。

#### 10、如何保证集合是线程安全的？

##### 一、典型回答

​	java提供了不同层面的线程安全支持。在传统集合框架内部，除了Hashtable等同步容器，还提供了所谓的同步包装器(Synchronized Wrapper)，我们可以调用Collections工具类提供的包装方法，来获取一个同步的包装容器，但是它们都是利用非常粗粒度的同步方式，在高并发情况下，性能比较低下。

​	更加普遍的选择是利用并发包提供的线程安全容器类，它提供了：各种并发容器，比如ConcurrentHashMap、CopyOnWriteArrayList。各种线程安全队列(Queue/Deque)，比如ArrayBlockingQueue、SynchronousQueue。各种有序容器的线程安全版本等。总的来说，并发包内提供的容器通用场景，远优于早期的简单同步实现。

##### 二、知识扩展

> 1、为什么需要ConcurrentHashMap？

​		Hashtable本身比较低效，因为它的实现基本就是将put、get、size等各种方法加上synchronize。

​		同步包装器Collections源码里，所有操作虽然不再声明成为synchronized方法，但是还是利用了this作为互斥的mutex，没有真正意义上的改进。

​		所以，Hashtable或者同步包装版本，都只是适合在非高度并发的场景下。

> 2、ConcurrentHashMap分析

​		早期ConcurrentHashMap，其实现是基于分离锁，也就是将内部进行分段(Segment)，里面则是HashEntry的数组，和HashMap类似，哈希相同的条目也是以链表形式存放。

​		HashEntry内部使用volatile的value字段来保证可见性，也利用了不可变对象的机制以改进利用Unsafe提供的底层能力，比如volatile access，去直接完成部分操作，以最优化性能，毕竟Unsafe中的很多操作都是JVM intrinsic优化过的。

​		Segment的数量默认16，可以由相应构造函数直接指定，需要注意的是必须是2的幂数值，例如指定15，会自动调整到16。

​		另外一个map的size方法需要同步，如果不同步，简单的计算所有的Segment的总值，可能会因为并发put，导致结果不准确，但是直接锁定所有Segment进行计算，就会变得非常昂贵，分离锁也限制了Map的初始化等操作。

		在java8和之后的版本中，总体结构上同步的粒度要更细致一些。内部仍然有Segment定义，但仅仅是为了保证序列化时的兼容性，不再有任何结构上的作用，因此初始化操作大大简化，修改为lazy-load形式。数据存储利用volatile来保证可见性。使用CAS等操作，在特定场景进行无锁并发操作。使用Unsafe、LongAdder之类底层手段，进行极端情况的优化。
#### 11、Java提供了哪些IO方式？

##### 一、典型回答

​	传统的java.io包，它基于流模型实现，提供了一些IO功能，比如File抽象、输入输出流等。交互方式是同步、阻塞的方式。好处是代码比较简单、直观，缺点是IO效率和扩展性存在局限性，容易成为应用性能的瓶颈。

​	很多时候，人们也把java.net下面提供的部分网络API，比如Socket、ServerSocket、HttpURLConnection也归类到同步阻塞IO类库，因为网络通信同样是IO行为。

​	在java1.4中引入了NIO框架(java.nio包)，提供了Channel、Selector、Buffer等新的抽象，可以构建多路复用的、同步非阻塞IO程序，同时提供了更接近操作系统底层的高性能数据操作方式。

​	在java7中，NIO有了进一步的改进，也就是NIO2，引入了异步非阻塞IO方式，也有很多人叫它AIO(Asynchronous IO)。异步IO操作基于事件和回调机制。

##### 二、知识扩展

​	区分同步或异步(synchronous/asynchronous)。同步是一种可靠的有序运行机制。异步则不需要等待，通常依靠事件、回调等机制来实现任务间次序关系。

​	区分阻塞与非阻塞(blocking/non-blocking)。当前线程处于阻塞状态，无法从事其他任务，只有当条件就绪才能继续。非阻塞则是不妨碍其他事物，可以在后台执行。

​	IO不仅仅是对文件的操作，网络编程中，比如Socket，都是典型的IO操作目标。输入流、输出流(InputStream/OutputStream)用于读取或写入字节的，而Reader/Writer则是用于操作字符。BufferedOutputStream等带缓冲区的实现，可以避免频繁的磁盘读写，进而提高IO处理效率，记得flush。很多IO工具类都实现了Closeable接口，因为需要进行资源的释放，利用try-with-resources、try-finally等机制保证资源释放，利用Cleaner或finalize机制作为资源释放的最后把关也是必要的。

​	NIO的主要组成部分：Buffer，高效的数据容器，除了布尔类型，所有原始数据类型都有相应的Buffer实现。Channel，类似Linux操作系统上看到的文件描述符，是更加操作系统底层的一种抽象，用于支持批量式IO操作。Selector，是实现多路复用的基础，它提供了一种高效的机制，可以检测到注册在Selector上的多个Channel中是否有Channel处于就绪状态，进而实现了单线程对多Channel的高效管理。

#### 12、Java有几种文件拷贝方式？

##### 一、典型回答

​	利用java.io类库，直接为源文件构建一个FileInputStream读取，然后再为目标文件构建一个FileOutputStream完成写入工作。

​	利用java.nio类库提供的transferTo或transferFrom方法实现。

​	总体上来说，NIO transferTo/From的方式可能更快，因为它更能利用现代操作系统底层机制，避免不必要拷贝和上下文切换。

##### 二、知识扩展

​	当使用输入输出流进行读写时，实际上是进行了多次上下文切换，比如应用读取数据时，先在内核态将数据从磁盘读取到内核缓存，再切换到用户态将数据从内核缓存读取到用户缓存。写入操作也是类似，仅仅是步骤相反。

​	而基于NIO transferTo的实现方式，在Linux和Unix上，则会使用到零拷贝技术，数据传输不需要用户态参与，省去了上下文切换的开销和不必要的内存拷贝，进而可能提高应用拷贝性能。在读取磁盘文件，进行Socket发送时，这种机制同样有效。

​	在程序中，使用缓存等机制，合理减少IO次数。

​	使用transferTo等机制，减少上下文切换和额外IO操作。

​	尽量减少不必要的转换过程。比如编解码，对象序列化和反序列化，比如操作文本文件或者网络通信，如果不是过程中需要使用文本信息，可以考虑不用将二进制信息转换成字符串，直接传输二进制信息。

#### 13、接口和抽象类有什么区别？
##### 一、典型回答

​	接口是对行为的抽象，它是抽象方法的集合，利用接口可以达到API定义和实现分离的目的。不能实例化。不能包含任何非常量成员，任何field都是隐藏着`pulic static final`的意义。没有非静态方法实现，要么是抽象方法，要么是静态方法。

​	抽象类是不能实例化的类，用abstract关键字修饰class，其目的主要是代码重用。除了不能实例化，形式上和一般的java类并没有太大区别，可以有一个或者多个抽象方法，也可以没有抽象方法。抽象类大多用于抽象相关java类的共用方法实现或者是共用成员变量，然后通过继承的方式达到代码复用的目的。java标准库中，比如collection框架，很多通用部分就被抽取成为抽象类，例如`java.util.AbstractList`。

##### 二、知识扩展

​	接口的职责也不仅仅限于抽象方法的集合，比如一类中没有任何方法的接口，通常叫作Marker Interface，顾名思义，它的目的就是为了声明某些东西，比如我们熟知的Cloneable、Serializable等。这似乎和Annotation异曲同工，对于Annotation，因为可以指定参数和值，在表达能力上要更强大一些，所以更多人选择使用Annotation。

​	java8增加了函数式编程的支持，即所谓functional interface，简单说就是只有一个抽象方法的接口，通常建议使用@FunctionalInterface注解来标记。Lambda表达式本身可以看作一类functional interface。

​	严格来说，java8以后，接口是可以有方法实现的。从java8开始，interface增加了对default method的支持。java9以后，可以定义private default method。Default method提供了一种二进制兼容的扩展已有接口的办法。比如java.util.Collection，它是collection体系的root interface，在java8中添加了一系列default method，主要是增加了Lambda、Stream相关的功能。

##### 三、面向对象设计

​	封装的目的是隐藏事务内部的实现细节，以便提供安全性和简化编程。比如在多线程环境暴露内部状态，导致的并发修改问题。封装这种隐藏，也提供了简化的界面，避免太多无意义的细节浪费调用者的精力。

​	继承是代码复用的基础机制，类似于对马、白马、黑马的归纳总结。但要注意，继承可以看作是非常紧耦合的一种关系，父类代码修改，子类行为也会变动。在实践中，过度滥用继承，可能会起到反效果。

​	多态，重写(verride)和重载(overload)、向上转型。

##### 四、SOLID原则

​	单一职责(Single Responsibility)，类或者对象最好是只有单一职责，在程序设计中如果发现某个类承担多种义务，可以考虑进行拆分。

​	开关原则(Open-Close,Open for extension,close for modification)，设计要对扩展开发，对修改关闭。程序设计应保证平滑的扩展性，尽量避免因为新增同类功能而修改已有实现，这样可以少产出些回归(regression)问题。

​	里式替换(Liskov Substitution)，进行继承关系抽象时，凡是可以用父类或者基类的地方，都可以用子类替换。

​	接口分离(interface Segregation)，在进行类和接口设计时，如果在接口里定义了太多方法，其子类很可能面临两难，就是只有部分方法对它是有意义的，这就破坏了程序的内聚性。对于这种情况，可以通过拆分功能单一的多个接口，将行为进行解耦。在未来维护中，如果某个接口设计有变，不会对使用其他接口的子类构成影响。

​	依赖反转(Dependency Inversion)，实体应该依赖于抽象而不是实现。也就是说高层次模块，不应该依赖于低层次模块，而是应该基于抽象。实践这一原则是保证产品代码之间适当耦合度的法宝。

​	现代语言的发展，很多时候并不是完全遵守前面的原则的，比如java10中引入了本地方法类型推断和var类型。按照，里氏替换原则，通常这样定义变量`List list = new ArrayList<>();`如果使用var类型`var list = new ArrayList();`理论上，这种语法上的便利，其实是增强了程序对实现的依赖，但是微小的类型泄漏却带来了书写的便利和代码可读性的提高，所以，实践中我们还是要按照得失利弊进行选择，而不是一味得遵循原则。

#### 14、谈谈你知道的设计模式？

##### 一、典型回答

​	理解和掌握典型的设计模式，有利于提高沟通、设计的效率和质量。

​	创建型模式，是对对象创建过程的各种问题和解决方案的总结，包括各种工厂模式(Factory、Abstract Factory)、单例模式(Singleton)、构建器模式(Builder)、原型模式(ProtoType)。

​	结构型模式，是针对软件设计结构的总结，关注于类、对象继承、组合方式的实践经验。包括桥接模式(Bridge)、适配器模式(Adapter)、装饰者模式(Decorator)、代理模式(Proxy)、组合模式(Composite)、外观模式(Facade)、享元模式(Flyweight)等。

​	行为型模式，是从类或对象之间交互、职责划分等角度总结的模式。比较常见的行为型模式有策略模式(Strategy)、解释器模式(Interpreter)、命令模式(Command)、观察者模式(Observer)、迭代器模式(Iterator)、模板方法模式(Template Method)、访问者模式(Visitor)。

​	例如单例模式。私有化无参构造、private static volatile单例变量，提供获取单例的方法，实现双检锁保证线程安全，利用懒加载改善初始内存开销。

​	例如构建器模式。为了优雅地解决构建复杂对象的麻烦，也就是需要输入的参数组合较多，用方法返回this的方式，实现fluent风格的API，也叫方法链。

​	在Spring框架中。BeanFactory和ApplicationContext应用了工厂模式。在Bean创建中，提供了单例和原型模式实现。AOP则使用了代理模式、装饰器模式、适配器模式。各种事务监听器，是观察者模式的典型应用。类似JdbcTemple等则是应用了模板模式。

#### 15、synchronized和ReentrantLock有什么区别呢？

##### 一、典型回答

​	synchronized是java内建的同步机制，所有也有人称其为Intrinsic Locking，它提供了互斥的语义和可见性，当一个线程已经获取当前锁时，其他视图获取的线程只能等待或者阻塞。

​	ReentrantLock再入锁是java5提供的锁实现，它的语义和synchronized基本相同。提供了很多实用的方法，能够是实现很多synchronized无法做到的细节控制，可以控制公平性(fairness)或者利用定义条件等。通过lock方法获取锁的同时，必须明确调用unlock方法释放锁。

​	早期版本 synchronized 在很多场景下性能相差较大，在后续版本进行了较多改进，在低竞争场景中表现可能优于 ReentrantLock。

##### 二、知识扩展

​	1、保证线程安全的两个办法：封装，通过封装可以将对象内部状态隐藏、保护起来。不可变，java语言目前还没有真正意义上的原生不可变，但是未来也许会引入。

​	2、线程安全的特性：原子性，相关操作不会中途被其他线程干扰，一般通过同步机制实现。可见性，是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将线程本地状态反映到主内存中，volatile就是负责保证可见性的。有序性，是保证线程内串行语义，避免指令重排等。

#### 16、synchronized底层如何实现？
##### 一、典型回答

​	synchronized代码块是由一对monitorenter/monitorexit指令实现的，Monitor对象是同步的基本实现单元。

​	在java6之前，Monitor的实现完全是依靠操作系统内部的互斥锁，因为需要进行用户态到内核态的切换，所以同步操作是一个无差别的重量级操作。现代的(Oracle)JDK中，JVM对此进行了大刀阔斧地改进，提供了三种不同的Monitor实现，分别是偏斜锁(Biased Locking)、轻量级锁和重量级锁，从而大大改进了其性能。

​	所谓锁的升级、降级，就是JVM优化synchronized运行的机制，当JVM检测到不同的竞争状况时，会自动切换到适合的锁实现。当没有竞争出现时，默认会使用偏斜锁。

​	JVM会利用CAS操作，在对象头上的Mark Word部分设置线程ID，以表示这个对象偏向于当前线程，所以并不涉及真正的互斥锁。在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定，使用偏斜锁可以降低无竞争开销。

​	如果有另外的线程视图锁定某个已经被偏斜过的对象，JVM就需要撤销(revoke)偏斜锁，并切换到轻量级锁实现。轻量级锁依赖CAS操作Mark Word来视图获取锁，如果重试成功，就使用普通的轻量级锁，否则进一步升级为重量锁。

#### 17、谈谈线程的生命周期和状态转移？

##### 一、典型回答

​	在java5以后，线程状态被明确定义在其公共内部枚举类型java.lang.Thread.State中，分别是：

- 新建(NEW)，表示线程被创建出来还没真正启动的状态，可以认为它是个java内部状态。
- 就绪(RUNNABLE)，表示该线程已经在JVM中执行，由于执行需要计算资源，或者还在等待系统分配给它CPU片段，在就绪队列里面排队。在其他一些分析中，会额外区分一种状态RUNNING，但是从java API的角度，并不能表示出来。
- 阻塞(BLOCKED)，表示线程在等待Monitor lock。比如，线程视图通过synchronized去获取某个锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。
- 等待(WAITING)，表示正在等待其他线程采取某些操作。一个常见的场景是类似生产者消费者模式，发现任务条件尚未满足，就让当前消费者线程等待(wait),另外的生产者线程去准备任务数据，然后通过类似notify等动作，通知消费线程可以继续工作了。Thread.join()也会令线程进入等待状态。
- 计时等待(TIMED_WAIT)，其进入条件和等待状态类似，但是调用的是存在超时条件的方法，比如wait或join等方法的指定超时版本。
- 终止(TERMINATED)，不管是意外退出还是正常执行结束，线程已经完成使命，终止运行，也有人把这个状态叫做死亡。

​	java线程是不允许启动两次的，第二次调用必然会抛出IllegalThreadStateException，这是一种运行时异常，多次调用会start被认为是编程错误。

##### 二、知识扩展

​	从操作系统的角度，线程是系统调度的最小单元，一个进程可以包含多个线程，作为任务的真正运作者，有自己的栈(Stack)、寄存器(Register)、本地存储(Thread Loacl)等,但是会和进程内其他线程共享文件描述符、虚拟地址空间等。

​	在具体实现中，线程还分内核线程、用户线程，java的线程实现其实是与虚拟机相关的。在java1.2之后，JDK已经抛弃了所谓的Green Thread，也就是用户调度的线程，现在的模型是一对一映射到操作系统内核线程。

​	近几年的Go语言等提供了协程(coroutine),大大提供了构建并发应用的效率。于此同时，java也在Loom项目中，孕育新的类似轻量级用户线程(Fiber)等机制，也许在不久的将来就可以在新版JDK中使用到它。

​	JVM的五个线程：

- main，主线程。
- Reference Handler，处理引用对象本身的垃圾回收
- Finalizer，处理用户的Finalizer方法。
- Signal Dispatcher,外部JVM命令的转发器。
- 在jdk6环境中，还有一个Attach Listener线程，负责接收外部命令的，比如jmap、jstack。

​	

#### 18、什么情况下Java程序会产生死锁？
##### 一、典型回答

​	死锁是一种特定的程序状态，在实体之间，由于循环依赖导致彼此一直处于等待之中，没有任何个体可以继续前进。死锁不仅仅是在线程之间发生，存在资源独占的进程之间同样也可能出现死锁。多线程场景中的死锁，指两个或多个线程之间，由于互相持有对方需要的锁，而永久处于阻塞的状态。

​	利用jstack等工具获取线程栈，定位互相之间的依赖关系，进而找到死锁。如果程序运行时发生了死锁，绝大多数情况都是无法在线解决的，只能重启、修正程序本身问题。所以，代码开发阶段互相审查，或者利用工具进行预防性排查，往往也是很重要的。

##### 二、知识扩展

​	区分线程状态->查看等待目标->对比Monitor等待有状态

​	开发自己的管理工具，可以使用java提供的标准管理API，ThreadMXBean的findDeadlockThreads()方法用于定位。在实际应用中，可以依此收集进一步的信息，进行预警等后续处理。但是要注意，对于线程进行快照本身是一个相对重量级的操作，还是要慎重选择频度和时机。

> 1、产生死锁的基本元素

​		互斥条件，类似java中Monitor都是独占的，要么是我用，要么是你用。互斥条件是长期持有的，在使用结束之前，自己不会释放，也不能被其他线程抢占。循环依赖关系，两个或者多个个体之间出现了锁的链条环。

> 2、方法一

​		尽量避免使用多个锁，并且只有需要时才持有锁。例如java NIO的实现代码向来以锁多著称，一个原因是，其本身模型就非常复杂，某种程度上不得不如此；另外就是在设计时，考虑到既要支持阻塞模式，又要支持非阻塞模式。直接结果就是，一个操作需要三个锁以上，在最近的一个JDK改进中，就发生了死锁现象。所以，从程序设计的角度反思，如果赋予一段程序太多的职责，出现既要又要的情况时，可能就需要审视下设计思路或者目的是否合理了。

> 3、方法二

​		如果必须使用多个锁，尽量设计好锁的获取顺序，可以参看著名的银行家算法。先将对象和锁之间的关系用图形化的方式表示出来，然后根据对象之间组合、调用的关系对比和组合，考虑可能调用时序，按照可能时序合并，发现可能死锁的场景。

> 4、方法三

​		使用带超时的方法，为线程带来更多可控性。类似Object.wait或者CountDownLatch.await方法，都支持所谓的itmed_wait,指定超时时间，为无法得到锁时准备退出逻辑。

​		并发Lock实现，如ReentrantLock还支持非阻塞式的获取锁操作tryLock(),这是一个插队行为(barging)，并不在乎等待的公平性，如果仅仅是对象恰巧没有被独占，则直接获取锁。一般采用条件允许时才插队，否则公平性规则等待。

> 5、方法四

​		业界也有一些其他方面的尝试，比如通过静态代码分析(如FindBugs)去查找固定的模式，进而定位可能的死锁或者竞争情况。

​		头痛的死锁，比如类加载过程发生的死锁，尤其是在框架大量使用自定义类加载时，因为往往不是在应用本身的代码库中，jstack等工具也不见得能够显示全部锁信息。对此java有官方文档进行了详细解释，并针对特定情况提供了相应JVM参数和基本原则。

#### 19、Java并发包提供了哪些并发工具类？

##### 一、典型回答

​	通常所说的并发包也就是java.util.concurrnet及其子包，集中了java并发的各种基础工具类，具体主要包括几个方面：
​	提供了比synchronized更加高级的各种同步结构，包括CountDownLatch、CylicBarrier、Semaphore等，可以实现更加丰富的多线程操作，比如利用Semaphore作为资源控制器，限制同时进行工作的线程数量。

​	各种线程安全的容器，比如最常见的ConcurrentHashMap、有序的ConcurrentSkipListMap，或者通过类似快照机制，实现线程安全的动态数组CopyOnWriteArrayList等。

​	各种并发队列实现，如各种BlockingQueue实现，比较典型的ArrayBlockingQueue、SynchronousQueue或针对特定场景的PriorityBlockingQueue等。

​	强大的Executor框架，可以创建各种不同类型的线程池，调度任务运行等，绝大部分情况下，不再需要自己从头实现线程池和任务调度器。

##### 二、知识扩展

​	java提供了典型信号量(Semaphore)的实现，通过控制一定数量的允许(permit)的方式，来达到限制通用资源访问的目的。

​	CountDownLatch,允许一个或多个线程等待某些操作完成。

​	CyclicBarrier，一种辅助性的同步结构，允许多个线程等待到达某个屏障。

​	java并发类库还提供了Phaser，功能与CountDownLatch很接近，但是它允许线程动态注册到Phaser上面。设计初衷是，实现多个线程类似步骤、阶段场景的协调，线程注册等待屏障条件触发，进而协调彼此间行动。

​	如果应用侧重于Map放入或者获取的速度，而不在乎顺序，推荐使用ConcurrentHashMap。反之则使用ConcurrentSkipListMap，对大量数据进行频繁地修改也同样适用。

​	CopyOnWriteArraySet是通过包装了CopyOnWriteArrayList来实现的，都会拷贝原数组，修改后替换原来的数组，通过这种防御性的方式，实现另类的线程安全。

#### 20、并发包中的ConcurrentLinkedQueue和LinkedBlockingQueue有什么区别？
##### 一、典型回答

​	通常习惯把并发包下面的所有容器叫做并发容器，实际上类似Concurrent开头的容器，才是真正代表并发。

​	Concurrent类型基于lock-free(无锁编程)，在常见的多线程访问场景，一般可以提供较高吞吐量。

​	LinkedBlockingQueue内部则是基于锁，并提供了BlockingQueue的等待性方法。

​	java.util.concurrent包提供的容器(Queue、List、Set)、Map，从命名上分为Concurrent、CopyOnWrite和Blocking三类。

​	Concurrent类型没有类似CopyOnWrite之类容器相对较重的修改开销。但是，Concurrent提供了较低的普遍一致性，也就是弱一致性，例如迭代器遍历时，如果容器发生修改，迭代器仍然可以继续进行遍历。另一个体现是，size等操作准确性是有限的，读取的性能具有一定的不确定性。与之对应的fail-fast(立即失败)，也就是检测到容器在遍历过程中发生了修改，则抛出ConcurrentModificationException,不再继续遍历。

##### 二、知识扩展

​	ConcurrentLinkedDeque和LinkedBlockingDeque。Deque(双端队列)的侧重点是支持对队列头尾都进行插入和删除，分别提供了尾部插入addList(e)、offerLast(e)，尾部删除removeLast()、pollLast()。

​	绝大部分Queue都是实现了BlockingQueue接口。Blocking意味着提供了特定的等待性操作，获取时(take)等待元素进队，或者插入时(put)等待队列出现空位。

​	ArrayBlockingQueue是最典型的有界队列，其内部以final的数组保存数据，数组的大小就决定了队列的边界，需要在创建时指定容量。LinkedBlockingQueue容易被误解为无边界，但其行为和内部代码都是基于有界的逻辑实现的，如果没有在创建队列指定容量，那么默认会被设置为Integer.MAX_VALUE，成为了无界队列。

​	SynchronousQueue，每个删除操作都要等待插入操作，反之每个插入操作也都要等待删除动作。其内部容量是0。

​	PriorityBlockingQueue是无边界的优先队列，其大小总归是要受系统资源影响。

​	DelayedQueue和LinkedTransferQueue同样是无边界的队列。对于无边界的队列，put操作永远也不会发生其他BlockingQueue的那种情况。

​	BlockingQueue基本都是基于锁实现，ArrayBlockingQueue的notEmpty、notFull都是同一个再入锁(ReentrantLock)的条件变量。而LinkedBlockingQueue则改进了锁操作的粒度，头尾操作使用不同的锁，所有在通用场景下，它的吞吐量相对要更好一些。

​	考虑应用场景中对队列边界的要求。ArrayBlockingQueue是有明确的容量限制的，而LinkedBlockingQueue则取决于是否在创建时指定，SynchronousQueue则干脆不能缓存任何元素。

​	从空间利用角度，数组结构的ArrayBlockingQueue要比LinkedBlockingQueue紧凑，因为其不需要创建所谓节点，但是其初始分配阶段需要一段连续的空间，所以初始内存需求更大。

​	通用场景中，LinkedBlockingQueue的吞吐量一般优于ArrayBlockingQueue，因为它实现了更加细粒度的锁操作。

​	ArrayBlockingQueue实现比较简单，性能更好预测，属于稳定选手。

​	如果需要实现两个线程之间接力性(handoff)的场景，SynchronousQueue是完美符合的，而且线程间协调和数据统一起来，代码更加规范。其性能表现，往往大大超过其它的实现，尤其是在队列元素较小的场景。

#### 21、Java并发类库提供的线程池有哪几种？

##### 一、典型回答

​	通常都是利用Executors提供的通用线程池创建方法，去创建不同配置的线程池，主要区别在于不同的ExecutorService类型或者不同初始参数。Executors目前提供了5种不同的线程池创建配置：

​	`newCachedThreadPool()`，它是一种用来处理大量短时间工作的任务线程池，具有几个鲜明特点：它会视图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过60秒，则被终止并移出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用SynchronousQueue作为工作队列。

​	`newFixedThreadPool(int nThreads)`，重用指定数目的线程，其背后使用的是无界的工作队列，任何时候最多有nThread个工作线程是活动的。这意味着，如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目nThreads。

​	`newSingleThreadExecutor()`，它的特点在于工作线程数目被限制为1，操作一个无界的工作队列，所以它保证了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目。

​	`newSingleThreadScheduledExecutor()`和`newScheduledThreadPool(int corePoolSize)`，创建的是个ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。

​	`newWorkStealingPool(int parallelism)`,这是一个经常被人忽略的线程池，java8才加入这个创建方法，其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序。

##### 二、知识扩展

​	Executor是一个基础的接口，其初衷是将任务提交和任务执行细节解耦。

​	ExecutorService则更加完善，不仅提供service的管理功能，比如shutdown等方法，也提供了更加全面的提交任务机制，如返回Future而不是void的submit方法。

​	java标准库提供了几种基础实现，比如ThreadPoolExecutor、ScheduledThreadPoolExecutor、ForkJoinPool。这些线程池的设计特点在于其高度的可调节性和灵活性，以尽量满足复杂多变的实际应用场景。

​	Executors则从简化使用的角度，提供了各种方便的静态工厂方法。

> 1、线程池实践

​	避免任务堆积。newFiedThreadPool是创建指定数目的线程，但其工作队列是无界的，如果工作线程数目太少，导致处理跟不上入队的速度，这就很可能占用大量系统内存，甚至出现OOM。诊断时，可以用jmap之类的工具查看是否有大量的任务对象入队。

​	避免过度扩展线程。通常在处理大量短时任务时，使用缓存的线程池，比如在最新的HTTP/2 client API中，目前的默认实现就是如此。在创建线程池的时候，并不能准确预计任务压力有多大、数据特征是什么样子，所以很难明确设定一个线程数目。

​	如果线程数目不断增长，也需要警惕另外一种可能性，就是线程泄漏，这种情况往往是因为任务逻辑有问题，导致工作线程迟迟不能被释放。建议排查下线程栈，很有可能多个线程都是卡在近似的代码处。

​	避免死锁等同步问题，进行死锁的排查。尽量避免在使用线程池时操作ThreadLocl。

> 2、线程池大小的选择策略

​	如果任务主要是进行计算，那么就意味着CPU的处理能力是稀缺的资源，如果线程太多，反倒可能导致大量的上下文切换开销。所以，这种情况，通常建议按照CPU核的数目N或者N+1。

​	如果是需要较多等待的任务，例如I/O操作比较多，可以参考Brain Goetz推荐的计算方法：线程数 = CPU核数*目标CPU利用率*(1 + 平均等待时间/平均工作时间)

​	实际还可能受各种系统资源限制影响，例如MacOSX大负载时ephemeral端口受限的情况。可用通过扩大可用端口范围解决，如果不能调整资源的容量，那么只能限制工作线程的数目了，可用是文件句柄、内存等。另外，除了调整线程池，很多时候框架上的改变更能解决问题，比如利用背压机制的ReactiveStream、合理的拆分等。

#### 22、AtomicInteger底层实现原理是什么？

##### 一、典型回答

​	AtomicInteger是对int类型的一个封装，提供原子性的访问和更新操作，其原子性操作的实现是基于CAS(compare-and-swap)技术。

​	所谓CAS，表征的是一些列操作的集合，获取当前数值，进行一些运算，利用CAS指令视图进行更新。如果当前数值未变，代表没有其他线程进行并发修改，则成功更新。否则，可能出现不同的选择，要么进行重试，要么就返回一个成功或者失败的结果。

​	AtomicInteger的内部属性可以看出，它依赖于Unsafe提供的一些底层能力，进行底层操作。

​	具体原子操作，例如getAndIncrement，Unsafe会利用value字段的内存地址偏移，直接完成操作。因为getAndIncrement需要返回数值，所以需要添加失败重试逻辑。而类似compareAndSet这种返回boolean类型的函数，所以需要重试。

​	CAS是java并发中所谓lock-free机制的基础。

##### 二、知识扩展

​	在数据库产品中，为保证索引的一致性，一个常见的选择是，保证只有一个线程能够排他地修改一个索引分区，如何在数据库抽象层面实现呢？

​	例如，以当前独占的线程ID作为锁的数值，通过原子操作设置lock数值，来实现加锁和释放锁。

​	在java中如果实现呢？Unsafe似乎不是个好的选择，例如这种java9中移除了Unsafe.moniterEnter()/moniterExit(),导致无法平滑升级到新的JDK版本。目前java提供了两种公共API，可以实现CAS操作，比如使用java.util.concurrent.atomic.AtomicLongFieldUpdater，它是基于反射机制创建，需要保证类型和字段名称正确。atomic包提供了最常用的原子性数据类型，甚至是引用、数组等相关原子类型和更新操作工具，是很多线程安全程序的首选。

​	如果是java9以后，完全可以采用另一种方式实现，也就是Variable Handle API，这是源于JEP 193，提供了各种粒度的原子或者有序性的操作等。推荐使用的原因，是其提供了精细度的公共底层API。也就是其API不会像内部API那样，发生不可预测的修改，这一点提供了对未来产品维护和升级的基础保障，很多额外工作量都是源于使用了Hack而非Solution的方式解决问题。

​	AbstractQueuedSynchronizer(AQS),其是java并发包中，实现各种同步结构和部分其他组成单元(如线程池中的Worker)的基础。Doug Lea曾经介绍过AQS的设计初衷。从原理上，一种同步结构往往是可以利用其他的结构实现的。但是对某种同步结构的倾向，会导致复杂、晦涩的实现逻辑，所以，他选择了将基础的同步相关操作抽象在AQS中，利用AQS为我们构建同步结构提供了范本。

​	AQS内部数据和方法，可以简单拆分为：一个volatile的整数成员表征状态，同时提供了setState和getState方法。一个先入先出(FIFO)的等待线程队列，以实现多线程间竞争和等待，这是AQS机制的核心之一。各种基于CAS的基础操作方法，以及各种期望具体同步结构去实现的acquire/release方法。利用AQS实现一个同步结构，至少要实现两个基本类型的方法，acquire获取资源独占权，release释放对某个资源的独占。

#### 23、请介绍类加载过程，什么是双亲委派模型？

##### 一、典型回答	

​	java的类加载过程分为三个主要步骤：

> 1、加载阶段(loading)

​	它是java将字节码数据从不同的数据源读取到JVM中，并映射为JVM认可的数据结构(Class对象)。数据源可能是各种各样的形态，如jar文件、class文件，甚至是网络数据源等。如果输入数据不是ClassFile的结构，则会抛出ClassFormatError。加载阶段是用户参与的阶段，可以自定义类加载器，去实现自己的类加载过程。

> 2、链接阶段(Linking)

把原始的类定义信息平滑地转化入JVM运行的过程中。细分为三个步骤：

- 验证(Verification)，这是虚拟机安全的重要保障，JVM需要核验字节信息是符合java虚拟机规范的，否则就被认为是VerifyError，这样就防止了恶意信息或者不合规的信息危害JVM的运行，验证阶段有可能触发更多的加载。
- 准备(Preparation)，创建类或接口中的静态变量，并初始化变量的初始值。则重点在于分配所需要的内存空间，不会去执行更进一步的JVM指令。
- 解析(Resolution)，将常量池中的符合引用(symbolic reference)替换为直接引用。

> 3、初始化阶段(initialization)

​	执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先与当前类型的逻辑。

​	双亲委派模型，简单说就是当类加载器(Class-Loader)视图加载某个类型的时候，除非父加载器找不到相应类型，否则尽量将这个任务代理给当前加载器的父加载器去做。使用委派模型的目的是避免重复加载java类型。

##### 二、知识扩展

​	启动类加载器(Bootstrap Class-Loader)，加载jre/lib下面的jar文件，如rt.jar。它是个超级公民，即使是在开启了Security Manager的时候，JDK仍赋予了它加载的程序AIIPermission。

​	扩展类加载器(Extension or Ext Class-Loader)，负责加载我们放到jre/lib/ext/目录下面的jar包，这就是所谓的extension机制。

​	应用类加载器(Application or App Class-Loader)，就是加载我们最熟悉的classpath的内容。系统(System)类加载器，其默认就是JDK内建的应用类加载器。

​	如果不同类加载器都自己加载需要的某个类型，那么就会出现多次重复加载，完全是种浪费。通常类加载机制有三个基本特征：

- 双亲委派模型。但不是所有类加载都遵循这个模型，有时候，启动类加载器所加载的类型，是可能要加载用户代码的，比如JDK内部的ServiceProvider/ServiceLocader机制，用户可以在标准API框架上，提供自己的实现，JDK也需要提供些默认的参考实现。例如，java中JNDI、JDBC、文件系统、Cipher等很多方面，都是利用的这种机制，这种情况就不会用双亲委派模型去加载，而是利用所谓的上下文加载器。
- 可见性，子类加载器可以访问父加载器加载的类型，但是反过来是不允许的，不然，因为缺少必要的隔离，我们就没有办法利用类加载器去实现容器的逻辑。
- 单一性，由于父加载器的类型对于子加载器是可见的，所以父加载器加载过的类型，就不会在子加载器中重复加载。但是注意，类加载器"邻居"间，同一类型仍然可以被加载多次，因为互相并不可见。

在JDK9中，由于Jigsaw项目引入了java平台模块化系统(JPMS)，java SE的源代码被划分为一系列模块。有了较大的改变。
#### 24、有哪些方法可以在运行时动态生成一个Java类？

##### 一、典型回答

​	可以事先准备一段源代码，直接用ProcessBuilder之类启动javac进程，并指定上面生成的文件作为输入，进行编译。最后，再利用类加载器，在运行时加载即可。

​	可以考虑使用java Compiler API，这是JDK提供的标准API，里面提供了与javac对等的编译器功能。

​	通常利用java字节码操纵工具和类库实现，用来生成字节码文件，交由类加载器去加载，比如ASM、javassist、cglib等。

##### 二、知识扩展

​	类从字节码到Class对象的转换，可以使用deineClass方法，或者defineClass的其他本地对等实现。JDK提供的defineClass方法，最终都是本地代码实现的。

​	对于一个普通的java动态代理，其实现过程可以简化成为：提供一个基础的接口，作为被调用类型(实现类)和代理类之间的统一入口。实现InvocationHandler，对代理对象方法的调用，会被分派到其invoke方法真正实现动作。通过Proxy类，调用其newProxyInstance方法，生成一个实现了相应基础接口的代理类实例。

​	字节码操纵技术，除了动态代理，还应用在各种Mock框架、ORM框架、IOC容器，部分Profiler工具，或者运行时诊断工具等，生成形式化代码的工具。字节码操纵技术是工具和基础框架必不可少的部分，大大减少了开发者的负担。

#### 25、谈谈JVM内存区域的划分，哪些区域可能发生OOM异常?

##### 一、典型回答
​	通常可以把JVM内存区域分为下面几个方面，其中，有的区域是以线程为单位，而有的区域则是整个JVM进程唯一的。

​	程序计数器(PC,Program Counter Register)。在JVM规范中，每个线程都有它自己的程序计数器，并且任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的java方法的JVM指令地址；或者，如果是在执行本地方法，则是未指定值(undefined)。

​	java虚拟机栈(java Virtual Machine Stack)，早期也叫java栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame)，对应着一次次的java方法调用。

​	同理程序计数器，在一个时间点，对应的只会有一个活动的栈帧，通常叫前帧，方法所在的类叫做当前类。如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，成为新的当前帧，一直到它返回结果或者执行结束。JVM直接对java栈的操作只有两个，就是对栈帧的压栈和出栈。

​	堆(Heap)，它是java内存管理的核心区域，用来放置java对象实例，几乎所有创建的java对象实例都是被直接分配在堆上。堆被所有的线程共享，在虚拟机启动时，指定的"Xmx"之类参数就是用来指定最大堆空间指标。堆也是垃圾收集器重点照顾的区域，所以堆内空间还会被不同的垃圾收集器进行进一步的细分，最有名的就是新生代、老年代的划分。

​	方法区(Method Area)。这也是所有线程共享的一块内存区域，用于存储所谓的元(Meta)数据，例如类结构信息，以及对应的运行时常量池、字段、方法代码等。由于早期的Hotspot JVM实现，很多人习惯将方法区称为永久代(Permanet Generation)。Oracle JDK8中将永久代移除，同时增加了元数据区(Metaspace)。

​	运行时常量池(Run-Time Constant Pool),这是方法区的一部分。反编译的类文件结构，可以看到版本号、字段、方法、超类、接口等各种信息，还有一项信息就是常量池。java的常量池可以存放各种常量信息，不管是编译器生成的各种字面量，还是需要在运行时决定的符合引用，所以它比一般语言的符号表存储的信息更加宽泛。

​	本地方法栈(Native Method Stack)。它和java虚拟机栈是非常相似的，支持对本地方法的调用，也是每个线程都会创建一个。在Oracle Hotspot JVM中，本地方法栈和java虚拟机栈是在同一块儿区域，这完全取决于技术实现的决定，并未在规范中强制。

##### 二、知识扩展

​	java中对OutOfMemoryError的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存。隐含着一层意思是，在抛出该异常之前，通常垃圾收集器会被触发，尽其所能去清理出空间。

​	堆内存不足是最常见的OOM原因之一，抛出的错误信息是java.lang.OutOfMemoryError:java heap space,原因可能是存在内存泄漏、堆大小不合理，或者JVM处理引用不及时导致堆积起来，内存无法释放等。

​	对于java虚拟机栈和本地方法栈，如果写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈，JVM就会抛出StackOverFlowError。如果JVM视图去扩展栈空间的时候失败，则会抛出OOM异常。

​	对于老版本的Oracle JDK，因为永久代的大小是有限的，并且JVM对永久代垃圾回收非常不积极，当不断添加新类型的时候，永久代出现OOM异常也非常多见，尤其是在运行时存在大量动态类型生成的场合。类似Intern字符串缓存占用太多空间，也会导致OOM问题。对应的异常信息，会标记出来和永久代相关java.lang.OutOfMemeoryError:PermGen space。

​	随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的OOM有所改观，出现OOM，异常信息则变成了java.lang.OutOfMemoryError:Metaspace。
​	直接内存不足，也会导致OOM。

#### 26、如何监控和诊断JVM堆内和堆外内存使用？

##### 一、典型回答

​	可以使用综合性的图形工具，如JConsole、VisualVM(从JDK9开始，VisualVM已经不再包含在JDK安装包中)等。

​	可以使用命令行工具，如jstat和jmap等工具都提供了一些选项，可以查看堆、方法区等使用数据。

​	也可以使用jmap等提供的命令，生成堆转储(Heap Dump)文件，利用jhat或Eclipse MAT等堆转储分析工具进行详细分析。

​	如果使用的是tomcat、weblogic等java EE服务器，这些服务器同样提供了内存管理相关的功能。

​	GC日志等输出，同样包含这非常丰富的信息。

​	对外内存中的直接内存，需要使用JDK自带的Native Memory Tracking(NMT)特性，他会从JVM本地内存分配的角度进行解读。

​	推荐使用java Mission Control(JMC)工具，其不仅能够使用JMX进行普通的管理、监控任务，还可以配合java Flight Recorder(JFR)技术，以非常低的开销，收集和分析JVM底层的Profiling和事件等信息。目前，Oracle已经将其开源，可以查看OpenJDK的MissionControl项目。

##### 二、知识扩展

> 1、新生代

​	是大部分对象创建和销毁的区域，在通常的java应用中，绝大部分对象生命周期都是很短暂的。其内部又分为Eden区域，作为对象初始分配的区域。两个Survivor，有时也叫from、to区域，被用来放置从Minor GC中保留下来的对象。

​	JVM会随意选取一个Survivor区域作为to，然后会在GC过程中进行区域间拷贝，也就是将Eden中存活下来的对象和from区域的对象，拷贝到to区域。这种设计主要是为了防止内存的碎片化，并进一步清理无用对象。

​	从内存模型角度对Eden区域进行划分，HotspotJVM还有一个概念叫做Thread Local Allocation Buffer(TLAB)。这是JVM为每个线程分配的一个私有缓存区域，否则多线程同时分配内存时，为避免操作同一地址，可能需要使用加锁等机制，进而影响分配速度。

> 2、老年代

​	放置长生命周期的对象，通常都是从Survivor区域拷贝过来的对象。普通对象会被分配在TLAB上，如果对象较大，JVM会视图直接分配在Eden其他位置上，如果对象太大，完全无法在新生代找到足够长的连续空闲空间，JVM就会直接分配到老年代。

> 3、永久代

​	这部分是早期HotspotJVM的方法区实现方式了，存储java类元数据、常量池、Intern字符串缓存，在JDK8之后就不存在了。

> 4、利用JVM参数，设置堆和内部区域的大小。

- 最大堆体积-Xmx value。

- 初始的最小堆体积-Xms value。

​	老年代和新生代的比例-XX:NewRatio=value，默认这个数值是2，意味着老年代是新生代的2倍大；换句话说，新生代是堆大小的1/3。可以直接设置新生代的大小-XX:NewSize=value。Eden和Survivor的大小是按照比例设置的，如果Survivor是8，那么Survivor区域就是Eden的1/8大小，也就是新生代的1/10，因为YoungGen=Eden+2*Survivor，JVM参数格式是-XX:SurvivorRatio=value。

#### 27、Java常见的垃圾收集器有哪些？
##### 一、典型回答

​	垃圾收集器(GC，：Garbage Collector)是和具体JVM实现紧密相关的，不同的厂商(IBM、Oracle)，不同的版本的JVM，提供的选择也不同。

> Serial GC

​	它是最古老的垃圾收集器，收集工作是单线程的，并且在进行垃圾收集过程中，会进入臭名昭著的stop-the-world状态。但由于其精简的GC实现，无需维护复杂的数据结构，初始化也简单，所以一直是Client模式下JVM的默认选项。从年代的角度，通常将其老年代实现单独称作Serial OId，它采用了标记-整理(Mark-Compact)算法。SerialGC对应JVM参数是：-XX:+UseSerialGC。

> ParNew GC，

​	是新生代GC实现，它实际是SerialGC的多线程版本，最常见的应用场景是配合老年代的CMS GC工作，其对应参数是-XX:+UseConcMarkSweepGC -XX:+UseParNewGC。

> CMS(Concurrent Mark Sweep)GC

​	基于标记-清除(Mark-Sweep)算法，设计目标是尽量减少停顿时间，这一点对于Web等反应时间敏感的应用非常重要，一直到今天，仍然有很多系统使用。但是，CMS采用标记-清除算法，存在着内存碎片化问题，所以难以避免在长时间运行等情况下发生fullGC，导致恶劣的停顿。另外，既然强调了并发(Concurrent),CMS会占用更多CPU资源，并和用户线程争抢。

> Parallel GC

​	在早期JDK8版本中，它是server模式JVM的默认GC选择，也被称作是吞吐量优先的GC。它的算法和SerialGC比较相似，尽管实现要复杂的多，其特点是新生代和老年代GC都是并行进行的，在常见的服务器环境中更加高效。开启参数是：-XX:UseParallelGC。设置暂停时间或吞吐量等目标，JVM会自动进行适应性调整，例如：-XX:MaxGCPauseMillis=value -XX:GCTimeRatio=N。

> G1 GC

​	是一种兼顾吞吐量和停顿时间的GC实现，是OracleJDK9以后的默认GC选项。G1可以直观的设定停顿时间的目标，相比与CMSGC，G1未必能做到CMS在最好情况下的延时停顿，但是最差情况要好很多。G1 GC仍然存在着年代的概念，但是其内存结构并不是简单的条带式划分，而是类似棋盘的一个个region。Region之间是复制算法，但整体上实际可看作是标记-整理(Mark-Compact)算法，可以有效地避免内存碎片，尤其是当java堆非常大的时候，G1的优势更加明显。G1吞吐量和停顿表现都非常不错，并且仍然在不断地完善，与此同时CMS已经在JDK9中被标记为废弃(deprecated)。

##### 二、知识扩展

​	引用计数算法，为对象添加一个引用计数，用于记录对象被引用的情况，如果计数为0,即表示对象回收。java并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。具体哪种最优是要看场景的，例如python是支持引用计数和垃圾收集机制。业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。

​	java选择的是可达性分析，这种类型的垃圾收集通常叫作追踪性垃圾收集(Tracing Garbage Collection)。其原理是将对象及其引用关系看作一个图，选定活动的对象作为GC Roots，然后跟踪引用链条，如果一个对象和GC Roots之间不可达，也就是不存在引用链条，那么即可认为是可回收对象。JVM会把虚拟机栈和本地方法栈中正在引用的对象、静态属性引用的对象和常量，作为GC Roots。

​	方法区无用元数据的回收。一般初始化类加载器加载的类型是不会进行类卸载(unload)的，而普通的类型的卸载，往往是要求相应自定义类加载器本身被回收，所有大量使用动态类型的场合，需要防止元数据区(或者早期的永久代)不会OOM。在8u40以后的JDK中，该参数是默认：-XX:+ClassUnloadingWithConcurrentMark。

​	复制(Copying)算法，在拷贝过程中将对象顺序放置，就可以避免内存碎片化。这么做的代价是，要进行复制，就要提前预留内存空间，有一定的浪费。对于G1这种分拆成大量Region的GC，复制而不是移动，意味着GC需要维护region之间对象引用关系，这个开销也不小，不管是内存占用或者时间开销。

​	标记-清除(Mark-Sweep)算法，首先进行标记工作，标识出所有要回收的对象，然后进行清除。这么做除了标记、清除过程效率有限，另外就是不可避免的出现碎片化问题，这就导致其不适合特别大的堆。否则一但出现Full GC，暂停时间可能根本无法接受。

​	标记-整理(Mark-Compact)，类似与标记-清除，但是为避免内存碎片化，它会在清理过程中将对象移动，以确保移动后的对象占用连续的内存空间。

​	通常把老年代GC叫做MajorGC，将对整个堆进行的清理叫做FullGC。

​	目前的默认选项G1 GC在不断的进行改进，很多原理认为的缺点，例如串行的FullGC、Card Table扫描的低效等，都已经被大幅改进，例如JDK10以后，FullGC已经是并行运行，在很多场景下，其表现还略优于ParallelGC的并行FullGC实现。

​	虽然SerialGC比较老，但是简单的设计和实现未必就是过时的，它本身的开销，不管是GC相关数据结构的开销，还是线程的开销，都是非常小的，所以随着云计算的兴起，在Serverless等新的应用场景下，SerialGC找到了新的舞台。

​	CMSGC因为其算法的理论缺陷等原因，虽然现在还有非常大的用户群体，但是已经被标记为废弃，如果没有组织主动承担CMS的维护，很有可能会在未来版本移除。

​	在JDK11中又增加了两种全新的GC方式：

- Epsilon GC，简单说就是个不做垃圾收集的GC，例如在进行性能测试的时候，可能需要明确判断GC本身产生了很多的开销，这是其典型应用场景。
- ZGC是Oracle开源出来的一个超级GC实现，具备令人惊讶的扩展能力，比如支持T bytes级别的堆大小，并且保证大部分情况下，延迟都不会超过10ms。目前还处于试验阶段，仅支持Linux64位的平台。

​	其他厂商也提供了各种独具一格的GC，例如比较有名的低延迟GC，Zing和Shenandoah等。

#### 28、谈谈你的GC调优思路?

##### 一、典型回答

​	从性能的角度看，通常关注三个方面，内存占用(footprint)、延时(latency)和吞吐量(throughput)，大多数情况下调优会侧重于一个或两个方面的目标，很少有情况可以兼顾三个不同的角度。除此之外也可以考虑其他GC相关的场景，例如，OOM也可能与不合理的GC相关参数有关。或者应用启动速度方面的需求，GC也会是个考虑的方面。

​	优化思路可以总结为:

> 1、理解应用需求和问题，确认调优目标。

​	假设开发了一个应用服务，但发现偶尔出现性能抖动，出现较长的服务停顿。评估用户可接受的响应时间和业务量，将目标简化为，希望GC暂停尽量控制在200ms以内，并且保证一定标准的吞吐量。

> 2、掌握JVM和GC的状态，定位具体的问题，确定有GC调优的必要。

​	通过jstat等工具查看GC等相关状态，可以开启GC日志，或者是利用操作系统提供的诊断工具等。例如，通过追踪GC日志，可以查找是不是GC在特定时间发生了长时间的暂停，进而导致了应用响应不及时。

> 3、选择的GC类型是否符合应用特征，如果是，具体问题表现在哪里，是MinorGC过长，还是MixedGC等出现异常停顿情况。如果不是，考虑切换什么类型，如CMS和G1都是更侧重于低延迟的GC选项。

> 4、通过分析确定具体调整的参数或者软硬件配置。

> 5、验证是否达到调优目标，如果达到目标，即可以考虑结束调优。否则，重新完成分析、调整、验证这个过程。

##### 二、知识扩展

​	G1 GC的内部结构和主要机制。

​	从内存区域的角度。其内部是类似棋盘状的一个个region组成(大小一致)，数值是在1M到32M字节之间的一个2的幂指数。JVM会尽量划分为2048左右、同等大小的region。

​	在G1实现中，年代是个逻辑概念。一部分region是作为Eden，一部分作为Survivor，除了OId region，G1会将超过region50%大小的对象(通常是byte或char)归类为Humongous对象，放置在相应的region中。

​	逻辑上，Humongous region算是老年代的一部分，因为复制这样的大对象是很昂贵的操作，并不适合新生代GC的复制算法。特别大的Humongous对象可以会占据多个region，这时就会导致空间的浪费，可以手动设置较大的region大小-XX:G1HeapRegionSize=nM。

​	从GC算法的角度，G1选择的是复合算法。在新生代，G1采用的仍然是并行的复制算法，所以同样会发生stop-the-world的暂停。在老年代，大部分情况下都是并发标记，而整理(compact)则是和新生代GC时捎带进行，并且不是整体性的整理，而是增量进行的。

​	Remembered Set，用于记录和维护region之间对象的引用关系。类似对象从Eden或者Survivor到to区域的"移动"，其实是"复制"，本质上是一个新的对象。所以在这个过程中，需要必须保证老年代到新生代的跨区引用仍然有效。

​	G1的很多开销都是源自Remembered Set，例如，它通常约Heap大小的20%或更高。并且在进行对象复制的时候，因为需要扫描和更改Card Table的信息，这个速度影响了复制的速度，进而影响暂停时间。

​	Humongous region通常会在并发标记结束后才进行回收。但在新版G1中，G1是记录了老年代region间对象引用，Humongous对象数量有限，所以能够够快速的知道是否有老年代对象引用它。如果没有，就只能是新生代了，但这个信息是可以在Young GC时就知道的，所以完全可以在YoungGC中进行Humongous对象的回收，不用像其他老年代对象那样，等待并发标记结束。

​	字符串排重的特性，在垃圾收集过程中，G1会把新创建的字符串对象放入队列中，然后YoungGC之后，并发地将内部数据一致性的字符串进行排重，也就是将其引用同一个数组，使用-XX:+UseStringDeduplication参数激活。

​	类型卸载问题，一个类只有当加载它的自定义类加载器被回收后才能被卸载，元数据区替换了永久代之后有所改善，但还是可能出现问题。可以利用-XX:+TraceClassUnloading参数查看类型卸载。

​	好在8u40以后，默认开启-XX:+ClassUnloadingWithConcurrentMark,在并发标记阶段结束后，JVM即进行类型卸载。但要知道老年代对象回收，基本要等待并发标记结束。也就意味着，如果标记结束不及时，导致堆已满，但老年代空间还没完成回收，就会触发Full GC。所以触发并发标记的时机很重要，早期的G1调优中，可以设置(-XX:InitiatingHeapOccupancyPercent)一个普适的数值，往往要根据运行结果调整。

​	在JDK9之后的G1实现中，这种调整需求会少很多，因为JVM只会将参数作为初始值，会在运行时进行采样，获取统计数据，然后据此动态调整并发标记启动时机。-XX:+G1UseAdaptiveIHOP默认开启。

​	在最新的JDK中，Full GC也是并行进行的了，在通用场景中的表现还由于ParallelGC的Full GC实现。

​	掌握GC调优信息收集途径。开启GC日志-XX:+PrintGCDetails，-XX:+PrintGCDateStamps。开启G1 Ergonomics相关信息-XX:+PrintAdaptiveSizePolicy。内部行为-XX:+PrintReferenceGC。并行引用处理-XX:+ParallelRefProcEnabled。

​	JDK9中JVM和GC日志机构进行了重构，PrintGCDetails已经标记为废弃，而PrintGCDateStamps已经被移除，可以使用java -Xlog:help查询新的配置参数。

​	如果发现YoungGC非常耗时，这很可能就是因为新生代太大了，可以考虑减小新生代的最小比例-XX:G1NewSizePercent。降低其最大值同样对降低YoungGC延迟有帮助-XX:G1MaxNewSizePercent。

​	如果MixedGC延迟较长。部分OId region会被包含进MixedGC，减少一次处理的region个数。可以设置提高MixedGC的个数，默认是8，数量增多，意味着每次被包含的region减少。-XX:G1MixedGCCountTarget。

#### 29、Java内存模型中的happen-before是什么？

##### 一、典型回答

​	Happen-before关系，是java内存模型中保证多线程操作可见性的机制，也是对早期语言规范中含糊的可见性概念的一个精确定义。

​	它的具体表现形式，包括但远不止是synchronized、volatile、lock操作顺序等方面。

​	例如：线程内执行的每个操作，都保证happen-before后面的操作，这就保证了基本的程序顺序规则，这是开发者在书写程序时的基本约定。

​	对于volatile变量，对它的写操作，保证happen-before在随后对该变量的读取操作。对于一个锁的解锁操作，保证happen-before加锁操作。对象构建完成，保证happen-before于finalizer的开始动作。甚至是类似线程内部操作的完成，保证happen-before其他Thread。join()的线程等。

​	happen-before关系是存在着传递性的，如果满足a happen-before b和b happen-before c，那么a happen-before c也成立。

​	它不仅仅是对执行时间的保证，也包括对内存读、写操作顺序的保证。仅仅是时钟顺序上的先后，并不保证线程交互的可见性。

##### 二、知识扩展

​	java对synchronized或volatile等，类似指令重排序时的行为，并没有提供清晰规范。指令重排序，既可以是编译器优化行为，也可能是源自于现代处理器的乱序执行等。换句话说，既不能保证一些多线程程序的正确性，例如双检索(Locking，DCL)的失效问题，可能导致未完整初始化的对象被访问，理论上这叫作并发编程中的安全发布(SafePublication)。也不能保证同一段程序在不同的处理器架构上表现一致，例如有的处理器支持换成一致性，有的不支持，各自都有自己的内存排序模型。

​	对于编译器、JVM开发者，关注点可能是如何使用类似内存屏障（Memory-Barrier）之类技术，保证执行结构符合JMM的推断。对于java应用开发者，则可能更加关注volatile、synchronized等语义，如果利用类似happen-before的规则，写出可靠的多线程应用。

​	JMM内部的实现通常是依赖于所谓的内存屏障，通过禁止某些重排序的方式，提供内存可见性保证，也就是实现了各种happen-before规则。同时需要尽量确保各种编译器、各种体系结构的处理器，都能够提供一致的行为。

#### 30、Java程序运行在Docker等容器环境有哪些新问题？

##### 一、典型回答

​	例如，其内存、CPU等资源限制是通过CGroup(Control Group)实现的，早期的JDK版本(8u131之前)并不能识别这些限制，进而会导致一些问题：如果未配置合适的JVM堆和元数据区、直接内存等参数，java就会有可能试图使用超过容器限制的内存，最终被容器OOM kill，或者自身发生OOM。错误判断了可获取的CPU资源，例如，Docker限制了CPU的核数，JVM就可能设置不合适的GC并行线程数等。

​	从应用打包、发布等角度出发，JDK自身就比较大，生成的镜像就更为臃肿，当镜像非常多的时候，镜像的存储等开销就会比较明显了。

​	如果考虑到微服务、Serverless等新的架构和场景，java自身的大小、内存占用、启动速度，都存在一定局限性，因为java早期的优化大多是针对长时间运行的大型服务器端应用。

##### 二、知识扩展

​	Docker并不是一种完全的虚拟化技术，而更是一种轻量级的隔离技术。Docker为每个容器提供了单独的命名空间，对网络、PID、用户、IPC通信、文件系统挂载点等实现了隔离。对于CPU、内存、磁盘IO等计算资源，则是通过CGroup进行管理。Docker仅在类似Linux内核之上实现了有限的隔离和虚拟化，并不是像传统虚拟化软件那样，独立运行一个新的操作系统。

​	如果是虚拟化的操作系统，不管是java还是其他程序，只要调用的是用一个系统API，都可以透明地获取所需的信息，基本不需要额外的兼容性改变。容器虽然省略了虚拟操作系统的开销，实现了轻量级的目标，但也带来了额外复杂性，它限制对于应用不是透明的，需要用户理解Docker的新行为。对于java来说，这样就带来了很多意外的困难。第一，容器环境对于计算资源的管理方式是全新的，CGroup作为相对比较新的技术，历史版本的java显然不能自然地理解相应的资源限制。第二，namspace对于容器内的应用细节增加了一些微妙的差异，比如jcmd、jstack等工具会依赖于"/proc//"下面提供的部分信息。但是Docker的设计改变了这部分信息的原有结构，需要对原有工具进行修改以适应这种改变。

​	从JVM运行机制的角度，这些导致OOM等问题实际反映了JVM如何根据系统资源(内存、CPU等)情况，在启动时设置默认参数。这就是所谓的Ergonomics机制，例如：JVM会大概根据检测到的内存大小，设置最初始启动时的堆大小为系统内存的1/64，并将堆最大值设置为系统内存的1/4。而JVM检测到系统的CPU核数，则直接影响到了ParallelGC的并行线程数目和JIT complier线程数目，甚至是应用中ForkJoinPool等机制的并行等级。

​	这些默认参数是根据通用场景选择的初始值。但是由于容器环境的差异，java的判断很可能是基于错误信息而做出的。更加严重的是JVM的一些原有诊断或备用机制也会受到影响。为保证服务的可用性，一种常见的选择时依赖-XX:OnOutOfMemoryError功能，通过调用处理脚本的形式来做一些补救措施，比如自动重启服务等。但是，这种机制是基于fork实现的，当java进程已经过度提交内存时，fork新的进程往往已经不能正常运行了。

​	升级到最新的JDK版本解决。JDK9中引入了一些实验性的参数，以方便Docker和java沟通，例如对内存限制-XX:+UnlockExperimentalVMOptions,-XX:+UseCGroupMemoryLimitForHeap。注意，这两个参数是顺序敏感的，并且只支持Linux环境。对于CPU核心数限定，java已经被修正为可以正确理解"-cpuset-cpus"等设置，无需单独设置参数。

​	如果是JDK10或者更新的版本。默认就会自适应各种资源限制和实现差异。UseCGroupMemoryLimitForHeap已经被标记废弃。新增了指定CPU核心的数目-XX:ActiveProcessorCount=n。如果实线中发现问题，也可以使用-XX:-UseContainerSupport关闭java的容器支持特性，这可以作为一种防御性机制，避免新特性破坏原有基础功能。

​	幸运的是，JDK9中的实验性改进已经被移植到JDK8u131中，并配置UseCGroupMemoryLimitForHeap，后续很有可能还会进一步将JDK10中相关的增强，应用到JDK8最新的更新中。

​	如果暂时只能使用老版本的JDK。建议，明确设置堆、元数据区等内存区域大小，保证java进程的总大小可控。明确配置GC和JIT并行线程数目，以避免二者占用过多计算资源。明确告知JVM系统内存限额，也可以指定Docker运行参数。

​	这是受操作系统Swappiness机制影响，当内存消耗达到一定门限，操作系统会试图将不活跃的进行换出(Swap out)，上面操作有显示关闭Swap的作用。

#### 31、你了解Java应用开发中的注入攻击吗？【31讲】
##### 一、典型回答

​	注入式(Inject)攻击是一类非常常见的攻击方式，其基本特征是程序允许攻击者将不可信的动态内容注入到程序中，并将其执行，这就可能完全改变最初预计的执行过程，产生恶意效果。

​	原则上提供了动态执行能力的语言特性，都需要提防发生注入攻击的可能。

​	例如最常见的SQL注入攻击。

​	操作系统命令注入。java语言提供了类似Runtime.exec(...)的API，可以用来执行特定命令。ls -la input_file_name,假设输入的是input_file_name;rm -rf /*，这就有可能出现问题了。实际上，java标准类库进行了非常多的改进，类似这种编程错误，未必可以真的完成攻击，但其反映的一类场景是真实存在的。

​	XML注入攻击。java核心类库提供了全面的XML处理、转换等各种API，而XML自身是可以包含动态内容的，例如XPATH，如果使用不当，可能导致访问恶意内容。

​	还有类似LDAP等允许动态内容的协议，都是可以利用特定命令，构造注入式攻击的，包括XSS(Cross-site Scripting)攻击，虽然并不和java直接相关，但也可能在JSP等动态页面中发生。

##### 二、知识扩展

​	哪些java API和工具构成了java安全基础？

> 第一，运行时安全机制。

​	限制java运行时的行为。在类加载过程中，进行字节码验证，以防止不合规的代码影响JVM运行或者载入其他恶意代码。

​	类加载器本身也可以对代码之间进行隔离，例如，应用无法获取启动类加载器(Bootstrap Class-Loader)对象实例，不同的类加载器也可以起到容器的作用，隔离模块之间不必要的可见性等。目前，Java Applet、RMI等特性已经或逐渐退出历史舞台，类加载等机制总体上反倒在不断简化。

​	利用SecurityManager机制和相关的组件，限制代码的运行时行为能力，其中可以定制policy文件和各种粒度的权限定义，限制代码的作用域和权限，例如对文件系统的操作权限，或者监听某个网络端口的权限等。

​	java的GC等资源回收管理机制，可以看作是运行时安全的一部分，如果相应机制失效，就会导致JVM出现OOM等错误，可看作是另类的拒绝服务。

> 第二，java提供的安全框架API，这是构建安全通信等应用的基础。

​	例如加密、解密API。授权、鉴权API。安全通信相关的类库，比如基本HTTPS通信协议相关标准实现，如TLS1.3或者附属的类似证书撤销状态判断(OSCP)等协议实现。

> 第三，JDK集成的各种安全工具。

​	例如keytool，这是个强大的工具，可以管理安全场景中不可或缺的秘钥、证书等，并且可以管理java程序使用的keystore文件。jarsigner，用于jar文件进行签名或者验证。在应用实践中，如果对安全要求非常高，建议打开SecurityManager，开启参数-Djava.security.manager，通常开启会导致10%~15%的性能下降，在JDK9以后，这个开销有所改善。

​	安全漏洞(Vulnerability)。按照传统定义，任何可以用来绕过系统安全策略限制的程序瑕疵，都可以算作安全漏洞。原因有很多，设计或实现中的疏漏、配置错误等，任何不慎都有可能导致安全漏洞出现，例如恶意代码绕过了java沙箱的限制，获取了权限等。

​	但是，要达到攻击的目的，未必都需要绕过权限限制。比如利用哈希碰撞发起拒绝服务攻击(DOS,Denial-Of-Service attack)。

​	针对SQL注入。在数据输入阶段，填补期望输入和可能输入之间的鸿沟。可以进行输入效验，限定什么类型的输入是合法的，例如，不允许输入标点符号等特殊字符，或者特定结构的输入。

​	在java应用进行数据库访问时，如果不用完全动态的SQL，而是利用PreparedStatement，可以有效防范SQL注入。不管是SQL注入，还是OS命令注入，程序利用字符串拼接生成运行逻辑都是个可能的风险点。

​	在数据库层面，如果对查询、修改等权限进行了合理限制，就可以在一定程度上避免被注入删除等搞破坏性的代码。

​	在安全领域，有一句准则：安全倾向于"明显没有漏洞"，而不是"没有明显漏洞"。为了更加安全可靠的服务，最好采取整体性的安全设计和综合性的防范手段，而不是头痛医头、脚痛医脚的修修补补，更不能心存侥幸。

​	普适的建议。尽量使用较新版本的JDK，并使用推荐的安全机制和标准。如果看过JDK release notes，例如8u141，就会发现JDK更新会修复已知的安全漏洞，并且会对安全机制等进行增强。

#### 32、如何写出安全的Java代码？【32讲】
##### 一、典型回答

​	DoS是一种常见的网络攻击，也称"洪水攻击"。利用大量机器发送请求，将目标网站的带宽或者其他资源消耗尽，导致其无法响应正常用户的请求。

​	从java语言的角度，更加需要重视的是程序级别的攻击，也就是利用java、JVM或应用程序的瑕疵，进行低成本的Dos攻击，这也是想要写出安全的java代码所必须考虑的：
​	如果使用的是早期的JDK和Applet等技术，攻击者构建合法但恶劣的程序就相对容易，例如，将其线程优先级设置为最高，做一些看起来无害但空耗资源的时期。幸运的是类似技术已经逐步退出历史舞台，在JDK9以后，相关模块就已经被移除。

​	哈希碰撞攻击是个典型的例子，对方可以轻易消耗系统有限的CPU和线程资源。从这个角度思考，类似加密、解密、图形处理等计算密集型任务，都要防范恶意滥用，以免攻击者通过直接调用或者间接触发方式，消耗系统资源。

​	利用java构建类似上传文件或者其他接受输入的服务，需要对消耗系统内存或存储的上限有所控制，不能将系统安全依赖于用户的合理使用。其中特别注意的是涉及解压缩功能时，就要防范Zip bomb等特定攻击。

​	另外，java程序中需要明确释放的资源有很多种，比如文件描述符、数据库连接，甚至是再入锁，任何情况下都应该保证资源释放成功，否则即使平时能够正常运行，也可能被攻击者利用而耗尽某类资源，这也算是可能的DoS攻击来源。

##### 二、知识扩展

​	安全问题实际就是软件的缺陷，软件安全既离不开设计、架构中的风险分析，也离不开编码、测试等阶段的安全实践手段。

​	数值类型需要防范溢出。java和JVM提供了很多基础性的改进，对于数组越界等处理，原生的避免了缓冲区溢出等攻击方式。但这并不代表完全杜绝了问题，java程序可以调用本地代码，也就是JNI技术，错误的数值可能导致C/C++层面的数据越界等问题。

​	敏感信息包含在异常信息中。尽量少暴露信息，也是保证安全的基本原则之一。即使并不认为某个信息有安全风险，建议如果没必要，不要暴露出来。对于安全标准特别高的系统，甚至可能要求敏感信息被使用后，要立即明确在内存中销毁，以免被探测。或者避免在发生core dump时，意外暴露。

​	java提供了序列化等创新的特性，广泛使用在远程调用等方面，但也带来了复杂的安全问题。针对序列化，建议敏感信息不要被序列化，在编码中，建议使用transient关键字将其保护起来。反序列化中，建议在readObject中实现与对象构建过程相同的安全检查和数据检查。在JDK9中，java引入了过滤器机制，以保证反序列化过程中数据都要经过基本验证才可以使用。其原理是通过黑名单和白名单，限定安全或者不安全的类型，并且可以进行定制，然后通过环境变量灵活进行配置，具体使用可以参考ObjectInputFilter。

​	前面的介绍，很多安全问题都源于非常基本的编程细节，类似Immutable、封装等设计，都存在着安全性的考虑。从实践角度，让每个人都了解和掌握这些原则，有必要但并不太现实。在实际开发中，各种功能点五花八门，未必能考虑的全面。没必要自己都去从头实现，尽量使用广泛验证过的工具、类库，不管是来自于JDK自身，还是Apache等第三方组织，都在社区的反馈下持续地完善代码安全。

​	开发过程中应用代码规约标准，是避免安全问题的有效手段。推荐来自孤尽的《阿里巴巴java开发手册》，以及其配套工具，充分总结了业界在java等领域的实践经验，将规约系统性地引入国内的软件开发，可以有效提高代码质量。不过规约会增加一定的开发成本，可能对迭代的节奏产生一定影响，所以对于不同阶段、不同需求的团队，可以根据自己的情况对规约进行适应性的调整。

​	以OpenJDK团队为例，应用了几个不同角度的实践：在早期设计阶段，就由安全专家组对新特性进行风险评估。开发过程中，尤其是code reviw阶段，应用OpenJDK自身定制的代码规范。利用多种静态分析工具如FindBugs、Parfait等，帮助早期发现潜在安全风险，并对相应问题采用零容忍态度，强制要求解决。甚至OpenJDK会默认将任何(编译等)警告，都当做错误对待，并体现在CI流程中。在代码check-in等关键环节，利用hook机制去调用规则检查工具，以保证不合规代码不能进入OpenJDK代码库。
​	

#### 33、后台服务出现明显“变慢”，谈谈你的诊断思路？
##### 一、典型回答

​	首先需要知道服务是突然变慢还是长时间运行后观察到变慢？类似问题是否重复出现？"慢"的定义是什么，我能够理解是系统对其他方面的请求的反应延时变长吗？

​	第二，理清问题的症状，便于定位具体的原因。初始判断key确认是否出现了意外的程序错误，例如检查应用本身的错误日志，对于分布式系统，很多公司都会实现更加系统的日志、性能等监控系统。一些java诊断工具也可以用于诊断，例如通过JFR(java Flight Recorder),监控应用是否大量出现了某种类型的异常。或者检查系统级别的资源等情况，监控CPU、内存等资源是否被其他进程大量占用。

​	监控java服务自身，例如GC日志里面是否观察到FullGC等恶劣情况出现，或者是否MinorGC在变长等，利用jstat等工具获取内存使用的统计信息、检查是否出现死锁等。

​	如果还不确定具体问题，对应用进行Profiling也是个办法，但因为它对系统产生侵入式，如果不是非常必要，大多数情况下并不建议在生产系统进行。

​	定位了程序错误或者JVM配置的问题后，就可以采取相应的补救措施，然后验证是否解决，否则还需要重复上面部分过程。

##### 二、知识扩展	

​	传统意义上的性能调优大多是针对单体应用的调优，性能分析方法论，Charlie Hunt曾将其方法论总结为两类：

- 自上而下。从应用的顶层，逐步深入到具体的不同模块，或者更近异步的技术细节单元，找到可能的问题和解决办法。这是常见的性能分析思路，也是大多数工程师的选择。
- 自下而上。从类似CPU这种硬件底层，判断类似Cache-Miss之类的问题和调优机会，出发点是指令级别优化。这往往是专业的性能工程师才能掌握的技能，并且需要专业工具配合，大多数是移植到新的平台上，或需要提供极致性能时才会进行。

​	例如，将大数据应用移植到SPARC体系结构的硬件上，需要对比和尽量释放性能潜力，但又希望尽量不该源代码。

> 采用自上而下分析思路。

​	系统性能分析中，CPU、内存和IO是主要关注项。对于CPU，可以先用top命令查看负载状况。可以看到其平均负载(load average)的三个值(分别是1分钟、5分钟、15分钟)非常低，并且暂时没有升高迹象。如果这些数值非常高(超过50%、60%)，并且短期平均值高于长期平均值，则表明负载很重。如果还有升高的趋势，那么就要非常警惕了。

​	进一步排查，找到最耗费CPU的java线程：利用top命令获取相应pid，"-H"代表thread模式，可以配合grep精准定位。然后转换成为16进制。最后利用jstack获取的线程栈，对比相应的id即可。

​	利用free之类查看内存使用。或者，进一步判断swap使用情况，top命令输出中Virt作为虚拟内存使用量，就是物理内存(Res)和swap求和，所以可以反推swap使用。

​	对于IO问题，既可能发生在磁盘IO，也可能是网络IO。例如，利用iostat等命令有助于判断磁盘的健康状况。

​	对于JVM层面的性能分析。利用JMC、JConsole等工具进行运行时监控。利用各种工具，在运行时进行堆转储分析，或者获取各种角度的统计数据(如jstat-gcutil分析GC、内存分带等)。GC日志等手段，诊断FullGC、MinorGC，或者引用堆积等。

​	对于应用Profiling，利用一些侵入的手段，收集程序运行时的细节，以定位性能问题瓶颈。所谓的细节，就是例如内存的使用情况、最频繁调用的方法是什么，或者上下文切换的情况等。一般不建议生产系统进行Profiling，大多数是在性能测试阶段进行。但是，当生产系统确实存在这种需求时，也不是没有选择。建议使用JFR配合JMC来做Profiling，因为它从HotspotJVM内部收集底层信息，并经过了大量优化，性能开销非常低，通常是低于2%的，并且如此强大的工具，也已经被Oracle开源出来。例如，在运行时启动JFR记录，并将这段时间的信息写入文件`:Jcmd <pid> JFR.start duration=120s filenam=myrecording.jfr`。然后，使用JMC打开.jfr文件就可以进行分析了，方法、异常、线程、IO等应有尽有，其功能非常强大。

​	找繁忙线程时，top -h ,再jstack，再换算tid比较累，而且jstack会造成停顿。推荐用vjtools里的vjtop,不断显示繁忙的java线程，不造成停顿。

#### 34、有人说“Lambda能让Java程序慢30倍”，你怎么看？

https://blog.overops.com/benchmark-how-java-8-lambdas-and-streams-can-make-your-code-5-times-slower/

##### 一、典型回答

这个争议实际反映了几个方面：

- 第一，基准测试是一个非常有效的通用手段，以直观、量化的方式，判断程序在特定条件下的性能表现。

- 第二，基准测试必须明确定义自身的范围和目标，否则很有可能产生误导的结果。前面代码片段的逻辑就有瑕疵，更过的开销是源于自动装箱、拆箱，而不是源自Lambda和Stream，所以得出的初始结论是没有说服力的。

- 第三，虽然Lambda/Stream为java提供了强大的函数式编程能力，但是也需要正

> 视其局限性：

​		一般来说，可以认为Lambda/Stream提供了与传统方式近对等的性能，但是如果对性能非常敏感，就不能完全忽视它在特定场景的性能差异了，例如：初始化的开销。Lambda并不是语法糖，而是一种新的工作机制，在首次调用时，JVM需要为其构建CallSite实例。这意味着，如果java应用启动过程引入了很多Lambda语句，会导致启动过程变慢。其实现特点决定了JVM对它的优化可能与传统方式存在差异。

​		增加了程序诊断等方面的复杂性，程序栈要复杂很多，Fluent风格本身也不算是对于调试非常友好的结构，并且在可检查异常的处理方面也存在着局限性等。

##### 二、知识扩展

> 什么时候需要开发微基准测试(Micro-Benchmark)？

​	微基准测试大多是API级别的验证，例如在开发共享类库，为其他模块提供某种服务的API等。API对于性能，如延迟、吞吐量有着严格的要求，例如实现了定制的HTTP客户端API，需要明确它对HTTP服务器进行大量GET请求时的吞吐能力，或者需要对比其他API，保证至少对等甚至更高的性能标准。

> 如何构建自己的微基准测试？

​	目前应用最广泛的框架之一就是JMH，OpenJDK自身也大量地使用JMH进行性能对比。JMH是有HotspotJVM团队专家开发的，除了支持完整的基准测试过程，包括预热、运行、统计和报告等，还支持java和其他JVM语言。更重要的是，它针对HotspotJVM提供了各种特性，以保证基准测试的正确性，整体准确性大大优于其他框架，并且，JMH还提供了用近似白盒的方式进行Profiling等工作的能力。

​	导入依赖，JMH利用注解，定义具体的测试方法，以及基准测试纤细配置。例如，至少要加上@Benchmark以标识它是个基准测试方法，而@BenchmarkMode则指定了基准测试模式，例如指定吞吐量(Throughput)模式，Mode.Throughput。或指定平均时间Mode.AverageTime等其他模式。实现具体的测试后，利用maven构建，及java -jar运行。

> 如何保证微基准测试的正确性？

​	由于执行的是非常有限的代码片段，必须要保证JVM优化过程不影响原始测试目的，下面几个方面需要重点关注：

​	保证代码经过了足够并且合适的预热。默认情况，在server模式下，JIT会在一段代码执行10000次后，将其编译为本地代码，client模式则是1500次以后。需要排除代码执行初期的噪音，保证真正采样到的统计数据符合其稳定运行状态。通常使用-XX:+PrintCompilation来判断预热工作到底经过了多久。建议再加上-Xbatch参数，否则JVM将默认开启后天编译，也就是在其他线程进行，可能导致输出的信息有些混淆。

​	防止JVM进行无效代码消除(Dead Code Elimination)，例如并没有使用的变量，那么JVM就可能直接判断无效代码，根本就不执行它。如果发现代码统计数据发生了数量级程度上的提高，需要警惕是否出现了该问题。解决办法就是尽量保证方法有返回值。或者使用JMH提供的BlackHole设施，使用blackhole.consume(mul);消除变量。

​	防止发生常量折叠(Constant Folding)。JVM如果发现计算法过程是依赖于常量或者事实上的常量，就可能会直接计算其结果，所以基准测试并不能真实反映代码执行的性能。JMH提供了State机制来解决这个问题，将本地变量修改为State对象信息。@State(Scope.Thread)。另外JMH还会对State对象进行额外的处理，以尽量消除伪共享(False Sharing)的影响。

​	如果希望确定方法内联(Inlining)对性能的影响，可以打开-XX:+PringInlining选项。

#### 35、JVM优化Java代码时都做了什么？

##### 一、典型回答

​	JVM在对代码执行的优化可分为运行时(runtime)优化和即时编译器(JIT)优化。
​	运行时优化主要是解释执行和动态编译通用的一些机制，比如锁机制(如偏斜锁)、内存分配机制(如TLAB)等。除此之外，还有一些专门用于优化解释执行效率的，比如模板解释器、内联缓存(inline cache,用于优化虚方法调用的动态绑定)。

​	即时编译器优化是指将热点代码以方法为单位转换成机器码，直接运行在底层硬件之上。它采用了多种优化方式，包括静态编译器可以使用的如方法内联、逃逸分析，也包括基于程序运行profile的投机性优化(speculative/optimistic optimization)。

​	JVM的优化方式仅仅作用在运行应用代码的时候，如果应用代码本身阻塞了，比如说并发时等待另一线程的结果，这就不在JVM的优化范畴了。

##### 二、知识扩展

​	java通过引入字节码这种中间表达方式，屏蔽了不同硬件的差异，由JVM负责完成从字节码到机器码的转化。

​	通常所说的编译期，是指javac等编译器或者相关API等将源码转换成为字节码的过程，这个阶段也会进行少量类似常量折叠之类的优化，利用反编译工具就可以直接查看细节。

​	javac优化与JVM内部优化也存在关联。例如java9中的字符串拼接，会被javac替换成对StringConcatFactory的调用，进而为JVM进行字符串拼接优化提供了统一的入口。在实际场景中，还可以通过不同的策略选项来干预这个过程。

​	解释器和编译器也会进行一些通用优化，例如锁优化。Intrinsic机制，或者叫做内建方法，就是针对特别重要的基础方法，JDK团队直接提供定制的实现，利用汇编或者编译器的中间表达方式编写，然后JVM会直接在运行时进行替换。不同体系结构的CPU在指令等层面存在着差异，定制才能充分发挥出硬件的能力。例如日常使用的典型字符串操作、数组拷贝等基础方法。

​	即时编译对java编译的基本单元是整个方法，通过对方法调用的计数统计，甄别出热点方法，编译为本地代码。另外一个优化场景，则是最针对所谓热点循环代码，利用通常说的栈上替换技术(OSR,On-Stack Replacement),如果方法本身的调用频度还不够编译标准，但是内部有大的循环之类，则还是会有进一步优化的价值。

​	JIT可以看作就是基于两个计数器实现，方法计数器和回边计数器提供给JVM统计数据，以定位到热点代码。实际中的JIT机制要复杂的多。

​	打印编译发生的细节，-XX:+PrintCompilation。输出更多编译的细节，-XX:UnlockDiagnosticVMOptions -XX:+LogCompilation -XX:LogFile=<your_file_path>，JVM会生成一个xml形式的文件，LogFile选项是可选的，不指定会输出到hostspot_pid<pid>.log。打印内联的发生-XX:+PrintInlining。CodeCache的使用状态，如JMC、JConsole、NMT之类工具。

​	调整热点代码门限值-XX:CompileThreshold=N。调整CodeCache大小-XX:ReservedCodeCacheSize=<size>,或调整其初始大小-XX:InitialCodeCacheSize=<size>。调整编译器线程数，或者选择适当的编译器模式-XX:CICompilerCount=N。减少进入安全点-XX:+PrintSafepointStatistics -XX:+PrintGCApplicationStoppendTime，例如在JIT过程中，逆优化等场景会需要插入安全点。常规的锁优化阶段也可能发生，比如，偏斜锁的设计目的是为了避免无竞争时的同步开销，但是当真的发生竞争时，撤销偏斜锁会触发安全点，是很重的操作，所有在并发场景中偏斜锁的价值其实是被质疑的，经常会明确建议关闭偏斜锁-XX:-UseBiasedLocking。
​	

#### 36、谈谈MySQL支持的事务隔离级别，以及悲观锁和乐观锁的原理和应用场景？

##### 一、典型回答

​	隔离级别(Isolation Level)，就是在数据库事务中，为保证并发数据读写的正确性而提出的定义，它并不是MySQL专有的概念，而是源于ANSI/ISO定制的SQL-92标准。

​	每种关系型数据库都提供了各自特色的隔离级别实现，虽然在通常的定义中以锁为实现单元，但实际的实现千差万别。以最常见的MySQL InnoDB引擎为例，它是基于MVCC(Multi-Versioning Concurrency Control)和锁的复合实现，按照隔离程度从低到高，MySQL事务隔离级别分为四个不同层次：

- 读未提交(Read uncommitted)
  - 就是一个事务能够看到其他事物尚未提交的修改，允许脏读出现。

- 读已提交(Read committed)
  - 事务能够看到的数据都是其他事物已经提交的修改，也就是保证不会看到任何中间性状态，脏读不会出现。读已提交并不能保证再次读取时能够获取同样的数据，也就是允许其他事物并发修改数据，允许不可重复读和幻像读(Phantom Read)出现。

- 可重复读(Repeatable reads)
  - 保证同一个事物中多次读取的数据是一致的，这是MySQL InnoDB引擎的默认隔离级别，但是和一些其他数据库实现不同的是，可以简单认为MySQL在可重复读级别不会出现幻像读。

​	串行化(Serializable)，并发事物之间是串行化的，通常意味着读需要获取共享读锁，更新需要获取排他写锁，如果SQL使用WHERE语句，还会获取区间锁(MySQL以GAP锁形式实现，可重复读级别中默认也会使用),这是最高的隔离级别。

​	至于悲观锁和乐观锁，也并不是MySQL或者数据库中独有的概念，而是并发编程的基本概念。主要区别在于，操作共享数据时，"悲观锁"即认为数据出现冲突的可能性更大，而"乐观锁"则是认为大部分情况不会出现冲突，进而决定是否采取排他性措施。

​	反映到MySQL数据库应用开发中，悲观锁一般就是利用类似SELECT...FOR UPDATE 这样的语句，对数据加锁，避免其他事物意外修改数据。乐观锁则与java并发包中AtomicFieldUpdater类似，也是利用CAS机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。

​	MVCC其本质就可以看作是中乐观锁机制，而排他性的读写锁、双阶段等则是悲观锁的实现。

​	从最广泛的应用开发者角度，至少需要掌握：

​	数据库设计基础，包括数据库设计中的几个基本范式，各种数据库的基本概念，例如表、视图、索引、外键、序列号生成器等，清楚如何将现实中业务实体和其依赖关系映射到数据库结构中，掌握典型实体数据应该使用什么样的数据库数据类型等。

​	每种数据库的设计和实现多少会存在差异，所以至少要精通使用过的数据库的设计要点。了解MVCC、Locking等机制对于处理进阶问题非常有帮助。还需要了解，不同索引类型的使用，甚至是底层数据结构和算法等。

​	常见的SQL语句，掌握基础的SQL调优技巧，至少要了解基本思路是怎样的，例如SQL怎样写才能更好利用索引、知道如何分析SQL执行计划等。

​	更进一步，至少需要了解针对高并发等特定场景中的解决方案，例如读写分离、分库分表，或者如何利用缓存机制等，目前的数据存储也远不止传统的关系型数据库了。

​	Hibernate是最负盛名的O/R Mapping框架之一，它也是一个JPA Provider。顾名思义，它是以对象为中心的，其强项更体现在数据库到java对象持久化功能。内部大量使用了Lazy-load等技术提高效率。并且，为了屏蔽数据库的差异，降低维护开销，Hibernate提供了类似SQL的HQL，可以自动生成某种数据库特定的SQL语句。

​	Hibernate应用非常广泛，但是过度强调持久化和隔离数据库底层细节，也导致了很多弊端，例如HQL需要额外的学习，未必比深入学习SQL语言更高效。减弱程序员对SQL的直接控制，还可能导致其他代价，本来一句SQL的事情，可能被Hibernate生成几条，隐藏的内部细节也阻碍了进一步的优化。

​	而MyBatis虽然任然提供了一些映射的功能，但更加以SQL为中心，开发者可以侧重于SQL和存储过程，非常简单、直接。如果应用需要大量高性能的或者复杂的SELECT语句等，"半自动"的MyBtis就会比Hibernate更加实用。

​	MyBatis架构自下而上分为基础支撑层、数据处理层、API接口层这三层。
​	基础支撑层，主要用来做连接管理、事务管理、配置加载、缓存管理等最基础组件，为上层提供最基础的支撑。

​	数据处理层，主要用来做参数映射、sql解析、sql执行、结果映射等处理，可以理解为请求到达，完成一次数据库操作的流程。

​	API接口层，主要对外提供API，提供诸如数据的增删改查、获取配置等接口。

#### 37、谈谈Spring Bean的生命周期和作用域？

##### 一、典型回答

> SpringBean生命周期比较复杂，可以分为创建和销毁两个过程。

- 实例化Bean对象。

- 设置Bean属性。

- 如果我们通过各种Aware接口声明了依赖关系，则会注入Bean对容器基础设施层面的依赖。具体包括BeanNameAware、BeanFactoryAware和ApplicationContextAware，分别会注入BeanID、BeanFactory或者ApplicationContext。

- 调用BeanPostProcessor的前置初始化方法postProcessBeforeInitialization。

- 如果实现了InitializingBean接口，则会调用afterPropertiesSet方法。

- 调用Bean自身定义的init方法。

- 调用BeanPostProcessor的后置初始化方法postProcessorAfterInitiallization。
  	创建过程完毕。

- SpringBean的销毁过程会依次调用DisposableBean的destroy方法和bean自身定制的destroy方法。

> SpringBean有五个作用域，其中最基础的有下面两种：

- Singleton，这是Spring的默认作用域，也就是为每个IOC容器创建唯一的一个Bean实例。
- Prototype,针对每个getBean请求，容器都会单独创建一个Bena实例。
  	如果是Web容器，则支持另外三种作用域：
  - Request，为每个HTTP请求创建单独的Bean实例。
  - Session，很显然Bean实例的作用域是Session范围。
  - GlobalSession，用于Portlet容器，因为每个Portlet有单独的Session，GlobalSession提供了一个全局性的HTTP Session。

##### 二、知识扩展

​	Spring的基础机制。控制反转(Inversion of Control)，或者也叫依赖注入(Dependency Injection)，广泛应用于Spring框架之中，可以有效地改善了模块之间的紧耦合问题。AOP，切面编程机制，Spring框架中的事物、安全、日志等功能都依赖于AOP技术。

​	Spring其实是狭义的Spring Framework，其内部包含了依赖注入、事件机制等核心模块，也包括事物、O/R Mapping等功能组成的数据访问模块，以及SpringMVC等Web框架和其他基础组件。

​	广义上的Spring已经成为了一个庞大的生态系统，例如：
​	SpringBoot，通过整合通用实践，更加自动、智能的依赖管理等，SpringBoot提供了各种典型应用领域的快速开发基础，所以它是以应用为中心的一个框架集合。

​	SpringCloud，可以看作是在SpringBoot基础上发展出的更加高层次的框架，它提供了构建分布式系统的通用模式，包含服务发现和服务注册、分布式配置管理、负载均衡、分布式诊断等各种子系统，可以简化微服务系统的构建。

​	SpringAOP自身设计和实现的细节。切面编程落实到软件工程其实是为了更好地模块化，而不仅仅是为了减少重复代码。通过AOP等机制，可以把横跨多个不同模块的代码抽离出来，让模块本身变得更加内聚，进而业务开发者可以更加专注于业务逻辑本身。从迭代能力上来看，可以通过切面的方式进行修改或者新增功能，这种能力不管是在问题诊断还是产品能力扩展中，都非常有用。

​	AOP Proxy的实现原理，它底层是基于JDK动态代理或者cglib字节码操纵等技术，运行时动态生成被调用类型的子类等，并实例化代理对象，实际的方法调用会被代理给相应的代理对象。

​	SpringAOP引入了其他几个关键概念：
​	Aspect，通常叫做方面，它是跨不同java类层面的横切性逻辑。在实现形式上，既可以是XML文件中配置的普通类，也可以在类代码中用"@Aspect"注解去声明。在运行时，Spring框架会创建类似Advisor来指代它，其内部会包括切入的时机(Pointcut)和切入的动作(Advice)。

​	Join Point,它是Aspect可以切入的特定点，在Spring里面只有方法可以作为Join Point。

​	Advice，它定义了切面中能够采取的动作。如果去看Spring源码，就会发现Advice、Join Point并没有定义在Sprig自己的命名空间里，这是因为他们是源自AOP联盟，可以看作是java工程师在AOP层面沟通的通用规范。

#### 38、对比Java标准NIO类库，你知道Netty是如何实现更高性能的吗？

##### 一、典型回答

​	单独从性能角度，Netty在基础的NIO等类库之上进行了很多改进，例如：
​	更加优雅的Reactor模式、灵活的线程模型、利用EventLoop等创新性的机制，可以非常高效地管理成百上千的Channel。

​	充分利用了java的Zero-Copy机制，并且从多种角度减低内存分配和回收的开销。例如，使用池化的Direct Buffer等技术，在提高IO性能的同时，减少了对象的创建和销毁。利用反射等技术直接操纵SelectionKey，使用数组而不是java容器等。

​	使用更多本地代码。例如，直接利用JNI调用Open SSL等方式，获得比java内建SSL引擎更好的性能。

​	在通信协议、序列化等其他角度的优化。

​	总的来说，Netty并没有java核心类库那些强烈的通用性、跨平台等各种负担，针对性能等特定目标以及Linux等特定环境，采取了一些极致的优化手段。

##### 二、知识扩展

​	Netty官方定义，它是一个异步的、基于事件Client/Server的网络框架，目标是提供一种简单、快速构建网络应用的方式，同时保证高吞吐量、低延时、高可靠性。

​	从设计思路和目的上，Netty与java自身的NIO框架相比有哪些不同？

​	java的标准库，由于其基础性、通用性的定位，往往过于关注技术模型上的抽象，而不是从一线应用开发者的角度去思考。开发者需要深入掌握线程、IO、网络等相关概念，学习路径很长，很容易导致代码复杂、晦涩，即使是有经验的工程师，也难以快速地写出高可靠性的实现。

​	Netty的设计强调了"Separation Of Concerns"，通过精巧设计的事件机制，将业务逻辑和无关技术逻辑进行隔离，并通过各种方便的抽象，一定程度上填补了基础平台和业务开发之间的鸿沟，更有利于在应用开发中普及业界的最佳实践。

​	另外，Netty>java.io+java.net。从API能力范围来看，Netty完全是javaNIO框架的一个大大的超集，除了核心的事务机制等，Netty还额外提供了很多功能，例如：
​	从网络协议的角度，Netty除了支持传输层的UDP、TCP、SCTP协议，也支持HTTP(s)、WebSocket等多种应用层协议，它并不是单一协议的API。

​	在应用中，需要将数据从java对象转换成为各种应用协议的数据格式，或者进行反向的转换，Netty为此提供了一系列扩展的编解码框架，与应用开发场景无缝衔接，并且性能良好。

​	它扩展了java NIO Buffer，提供了自己的ByteBuf实现，并且深度支持Direct Buffer等技术，甚至hack了java内部对Direct Buffer的分配合销毁等。同时，Netty也提供了更加完善的Scatter/Gather机制实现。

​	ServerBootstrap，服务器端程序的入口，这是Netty为简化网络程序配置和关闭等生命周期管理，所引入的Bootstrapping机制。通常要做的创建Channel、绑定端口、注册Handler等，都可以通过这个统一的入口，以Fluent API等形式完成，相对简化了API使用。与之相对应，Bootstrap则是Client端的通常入口。

​	Channel，作为一个基于NIO的扩展框架，Channel和Selector等概念仍然是Netty的基础组件，但是针对应用开发具体需求，提供了相对易用的抽象。

​	EventLoop，这是Netty处理事件的核心机制。例子中使用了EventLoopGroup。在NIO中通常要做的几件事，如注册感兴趣的事件、调度相应的Handler等，都是EventLoop负责。

​	ChannelFuture，这是Netty实现异步IO的基础之一，保证了同一个Channel操作的调用顺序。Netty扩展了java标准的Future，提供了针对自己场景的特有Future定义。

​	ChannelHandler，这是应用开发者放置业务逻辑的主要地方，也是"Separation Of Concerns"原则的体现。

​	ChannelPipeline，它是ChannelHandler链条的容器，每个Channel在创建后，自动被分配一个ChannelPipeline。

#### 39、谈谈常用的分布式ID的设计方案？Snowflake是否受冬令时切换影响？

##### 一、典型回答

​	分布式ID定义的基本要求全局唯一和有序性。

​	典型方案包括：
​	基于数据库自增序列的实现，好处是简单易用，但是在扩展性和可靠性等方面存在局限性。

​	基于Twitter早期开源的Snowflake的实现，以及相关改动方案，这是目前应用相对比较广泛的一种方式，其结构定义整体长度通常是64(1+41+10+12=64)位，适合使用java语言中的long类型存储。头部是1位的正负标识位。41位时间戳，通常使用System.currentTimeMillis()。10位的WorkerID，标准定义是5位数据中心+5位机器ID，组成了机器编号，以区分不同的集群节点。12位就是单位毫秒内可生成的序列号数目的理论极限。

​	Snowflake的官方版本是基于Scala语言，java等其他语言的参考实现有很多，是一种非常简单实用的方式，具体位数的定义是可以根据分布式系统的真实场景进行修改的，并不一定要严格按照示意图中的设计。

​	Redis、Zookeeper、MongoDB等中间件，也都有各种唯一ID解决方案。其中一些设计也可以算作是Snowflake方案的变种。例如MongoDB的ObjectId提供了一个12byte(96位)的ID定义，其中32位用于记录以秒为单位的时间，机器ID则是23位，16位用作进程ID，24位随机起始的计数序列。

​	国内的一些大厂开源了其自身的部分分布式ID实现，InfoQ就曾经介绍过微信的seqsvr，它采取了相对复杂的两层架构，并根据社交应用的数据特定进行了针对性设计，具体参考相关代码实现。另外百度、美团也都有开源或者分享了不同的分布式ID实现，都可以进行参考。

​	Snowflake是否受冬令时切换影响？我认为没有影响，你可以从Snowflake的具体算法实现寻找答案。Snowflake算法的java实现大都是依赖于System.currentTimeMillis()，这个数值代表什么呢？从javadoc可以看出，它是返回当前时间和1970年1月1号UTC时间相差的毫秒数，这个数值与夏/冬令时并没有关系，所以并不受其影响。

​	除了唯一和有序，考虑到分布式系统的功能需要，通常还会额外希望分布式ID保证：
​	有意义，或者说包含更多信息，例如时间、业务等信息。这一点和有序性要求存在一定关联，如果ID中包含时间，本身就能保证一定程度的有序，虽然并不能绝对保证。ID中包含额外信息，在分布式数据存储等场合中，有助于进一步优化数据访问的效率。

​	高可用性，这是分布式系统的必然要求。

​	紧凑性，ID的大小可能受到实际应用的制约，例如数据库存储往往对长ID不友好，太长的ID会降低MySQL等数据库索引的性能。编程语言在处理时也可能受数据类型长度限制。

​	在具体的生产环境中，还有可能提出对QPS等方面的具体要求，尤其是在国内的一线互联网公司的业务规模下，更是需要考虑峰值业务场景的数量级层次需求。

​	对于数据库自增方案，除了实现简单，它生成的ID还能够保证固定步长的递增，使用很方便。但是，因为每获取一个ID就会触发数据库的写请求，是一个代价高昂的操作，构建高扩展性、高性能解决方案比较复杂，性能上限明显，更不要谈扩容等场景的难度了。与此同时，保证数据库方案的高可用性也存在挑战，数据库可能发生宕机，即使采取主从热备等各种措施，也可能出现ID重复等问题。实际大厂商往往是构建了多层的复合架构，例如美团公开的数据库方案Leaf-Segment，引入了起到缓存等作用的Left层，对数据库操作则是通过数据库中间件提供的批量操作，这样既能保证性能、扩展性，也能保证高可用。但是，这种方案对基础架构层面的要求很多，未必适合普通业务规模的需求。

​	与之相比，Snowflake方案的好处是算法简单，依赖也非常少，生成的序列可预测，性能也非常好，比如Twitter的峰值超过10万/s。但是，它也存在一定的不足，例如：
​	时钟偏斜问题(Clock Skew)。普通的计算机系统时钟并不能保证长久的一致性，可能发生时钟回拨等问题，这就会导致时间戳不准确，进而产生重复ID。针对这一点，Twitter曾经在文档中建议开启NTP，毕竟Snowflake对时间存在依赖，但是也有人提议关闭NTP。个人认为还是应该开启NTP，只是可以考虑stepback设置为0，以禁止回调。从设计和具体编码的角度，还有一个很有效的措施就是缓存历史时间戳，然后在序列生成之前进行检验，如果出现当前时间落后于历史时间的不合理情况，可以采取相应的动作，要么重试、等待时钟重新一致，或者就直接提示服务不可用。

​	另外，序列号的可预测性是把双刃剑，虽然简化了一些工程问题，但很多业务场景并不适合可预测的ID。如果用它作为安全令牌之类，则是非常危险的，很容易被黑客猜测并利用。

​	ID设计阶段需要谨慎考虑暴露出的信息。例如，Erlang版本的flake实现基于MAC地址计算WorkerID，在安全敏感的领域往往是不可以这样使用的。

​	从理论上来说，类似Snowflake的方案由于时间数据位数的限制，存在与2038年问题相似的理论极限。







